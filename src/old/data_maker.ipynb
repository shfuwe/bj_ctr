{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这一步主要做数据清洗和数据格式化。age和gender给出的数据形式为多值概率，所以选取概率最大的作为用户的基本属性。picnum和pubtime存在一些不符合预期的特征值，需要先做特征清洗。受限于资源限制，所以训练集只保留了两天的数据，而且按照0.01的比例进行了下采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0           1          2              3  4   5\n",
      "0          0  2204868548  464495940  1625011774995  2   4\n",
      "1          1  1623790870  464553715  1625066054894  2   2\n",
      "2          2  1637010070  464687570  1625053546711  2  10\n",
      "3          3  1634251474  464661865  1625047014335  2  10\n",
      "4          4  2352721164  464692079  1625035383911  2  11\n",
      "...      ...         ...        ...            ... ..  ..\n",
      "49995  49995  1640585246  464553715  1625036568698  2   1\n",
      "49996  49996  1987843480  464382231  1625009469794  2   1\n",
      "49997  49997  2391080328  464617167  1625027566512  5   1\n",
      "49998  49998   125699342  464172118  1625034692217  2  11\n",
      "49999  49999  2154437014  464225813  1625008637470  2   3\n",
      "\n",
      "[50000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test_info = pd.read_table('../data/test_info.txt',header=None)\n",
    "print(test_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data\n",
      "   id      userid      docid      timestamp  network  refresh  \\\n",
      "0   0  2204868548  464495940  1625011774995        2        4   \n",
      "1   1  1623790870  464553715  1625066054894        2        2   \n",
      "2   2  1637010070  464687570  1625053546711        2       10   \n",
      "3   3  1634251474  464661865  1625047014335        2       10   \n",
      "4   4  2352721164  464692079  1625035383911        2       11   \n",
      "\n",
      "                                dt        date  \n",
      "0 2021-06-30 08:09:34.995000+08:00  2021-06-30  \n",
      "1 2021-06-30 23:14:14.894000+08:00  2021-06-30  \n",
      "2 2021-06-30 19:45:46.711000+08:00  2021-06-30  \n",
      "3 2021-06-30 17:56:54.335000+08:00  2021-06-30  \n",
      "4 2021-06-30 14:43:03.911000+08:00  2021-06-30  \n"
     ]
    }
   ],
   "source": [
    "test_info.columns = ['id', 'userid', 'docid', 'timestamp', 'network', 'refresh']\n",
    "test_info['dt'] = pd.to_datetime(test_info['timestamp'], utc=True,\n",
    "                               unit='ms').dt.tz_convert('Asia/Shanghai')\n",
    "test_info['date'] = test_info['dt'].dt.date\n",
    "test_info['date'] = test_info['date'].astype('str')\n",
    "print('test data')\n",
    "print(test_info.head())\n",
    "test_info.to_pickle('../data/test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/news_info.txt', 'r') as fd:\n",
    "    doc_text = fd.read().split('\\n')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(347466, 7)\n"
     ]
    }
   ],
   "source": [
    "doc_data = list()\n",
    "for text in doc_text:\n",
    "    doc_data.append(text.split('\\t'))\n",
    "    \n",
    "doc_info = pd.DataFrame(doc_data)\n",
    "doc_info.columns = ['docid', 'title', 'pubtime', 'picnum', 'category1st', 'category2nd', 'keyword']\n",
    "print(doc_info.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 35.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc info\n",
      "       docid                         title        pubtime  picnum  \\\n",
      "0  325279629                    合集|外交部每日答问  1624889500000       0   \n",
      "1  334493096             汽车点评网友“毛蒙”分享的小视频“  1563404900000       0   \n",
      "2  341014580  抖音爆红车模小姐姐,可爱如神仙,如今大火的她还玩起这个!  1567067600000       3   \n",
      "3  344297472      一夜能挣30万的网红车模,她的捞金神器竟是这个!  1569240500000       3   \n",
      "4  347286095  男子购买假号牌被查,后备箱找到真车牌,车主直言不愿太高调  1571271100000       3   \n",
      "\n",
      "   category1st  category2nd                                            keyword  \n",
      "0            0            0                                                     \n",
      "1           23          115                                     https:8.135272  \n",
      "2           11           56  初恋:11.052198,吊坠:9.525825,吊坠^^耳环:7.982950,妆容:10...  \n",
      "3           11           56  主播:10.299306,发展:7.355088,可爱:8.705284,清纯:10.108...  \n",
      "4           23          117  买车:9.357286,交警:8.964902,交通:7.790495,交通^^秩序:10....  \n"
     ]
    }
   ],
   "source": [
    "# picnum和pubtime存在一些不符合预期的特征值，需要先做特征清洗\n",
    "# 脏数据\n",
    "def clean_picnum(x):\n",
    "    if x in ['上海', '云南', '山东', 'NoneType',''] or x is None: return 0\n",
    "    else: \n",
    "#         print(x)\n",
    "        return int(float(x))\n",
    "\n",
    "doc_info['picnum'] = doc_info['picnum'].apply(lambda x: clean_picnum(x))\n",
    "\n",
    "# 脏数据\n",
    "def clean_pubtime(x):\n",
    "    try:   \n",
    "        x=int(float(x))\n",
    "        return x\n",
    "    except:\n",
    "        print(x)\n",
    "        return 0\n",
    "#     if type(x) == str: return 0\n",
    "#     else: return x\n",
    "\n",
    "doc_info['pubtime'] = doc_info['pubtime'].apply(lambda x: clean_pubtime(x))\n",
    "\n",
    "\n",
    "for col in tqdm(['category1st', 'category2nd']):\n",
    "    lbe = LabelEncoder()\n",
    "    doc_info[col] = doc_info[col].fillna('NAN')\n",
    "    doc_info[col] = lbe.fit_transform(doc_info[col])\n",
    "\n",
    "print('doc info')\n",
    "print(doc_info.head())\n",
    "doc_info.to_pickle('../data/doc_info.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0              1        2    3    4  \\\n",
      "0             17340        iPhoneX      IOS   上海   上海   \n",
      "1            394666       ARS-TL00  Android   吉林   白山   \n",
      "2            413322       iPhoneXS      IOS   北京   北京   \n",
      "3            450280       NOH-AN00  Android   湖北   武汉   \n",
      "4            456646      M2102J2SC  Android   广东   中山   \n",
      "...             ...            ...      ...  ...  ...   \n",
      "1029713  2446592934  RedmiNote7Pro  Android   江苏   常州   \n",
      "1029714  2446592956            NaN      NaN  NaN  NaN   \n",
      "1029715  2446592962         V2002A  Android   广东   惠州   \n",
      "1029716  2446592980            NaN      NaN  NaN  NaN   \n",
      "1029717  2446593010            NaN      NaN  NaN  NaN   \n",
      "\n",
      "                                                         5  \\\n",
      "0        A_0_24:0.029774,A_25_29:0.126834,A_30_39:0.789...   \n",
      "1        A_0_24:0.400583,A_25_29:0.261192,A_30_39:0.268...   \n",
      "2        A_0_24:0.000076,A_25_29:0.017034,A_30_39:0.972...   \n",
      "3        A_0_24:0.943772,A_25_29:0.043366,A_30_39:0.011...   \n",
      "4        A_0_24:0.024724,A_25_29:0.230098,A_30_39:0.409...   \n",
      "...                                                    ...   \n",
      "1029713  A_0_24:0.082798,A_25_29:0.176158,A_30_39:0.400...   \n",
      "1029714  A_0_24:0.057814,A_25_29:0.234357,A_30_39:0.382...   \n",
      "1029715  A_0_24:0.210524,A_25_29:0.214230,A_30_39:0.326...   \n",
      "1029716  A_0_24:0.127754,A_25_29:0.254640,A_30_39:0.317...   \n",
      "1029717                                                NaN   \n",
      "\n",
      "                                     6  \n",
      "0        female:0.000000,male:1.000000  \n",
      "1        female:0.000000,male:1.000000  \n",
      "2        female:0.191682,male:0.808318  \n",
      "3        female:0.198083,male:0.801917  \n",
      "4        female:0.335419,male:0.664581  \n",
      "...                                ...  \n",
      "1029713  female:0.360714,male:0.639286  \n",
      "1029714  female:0.475299,male:0.524701  \n",
      "1029715  female:0.455395,male:0.544605  \n",
      "1029716  female:0.437225,male:0.562775  \n",
      "1029717                            NaN  \n",
      "\n",
      "[1029718 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "user_info = pd.read_table('../data/user_info.txt',header=None)\n",
    "print(user_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:02<00:00,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user info\n",
      "   userid  device  os  province  city  age  gender\n",
      "0   17340    2642   1       185   291    2       2\n",
      "1  394666     160   0       207   571    0       2\n",
      "2  413322    2644   1       200   340    2       2\n",
      "3  450280    1381   0       244   502    0       2\n",
      "4  456646    1167   0       224   298    2       2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "user_info.columns = [\n",
    "    'userid', 'device', 'os', 'province', 'city', 'age', 'gender'\n",
    "]\n",
    "\n",
    "def get_cate(x):\n",
    "    if type(x) == float:\n",
    "        return x\n",
    "    li = x.split(',')\n",
    "    res = list()\n",
    "    for i in li:\n",
    "        lbl, prob = i.split(':')\n",
    "        res.append([lbl, float(prob)])\n",
    "    res = sorted(res, key=lambda x: x[1])\n",
    "    return res[-1][0]\n",
    "\n",
    "\n",
    "user_info['age'] = user_info['age'].apply(lambda x: get_cate(x))\n",
    "user_info['gender'] = user_info['gender'].apply(lambda x: get_cate(x))\n",
    "\n",
    "# label encoding 数字化\n",
    "for col in tqdm(\n",
    "    ['device', 'os', 'province', 'city', 'age', 'gender']):\n",
    "    lbe = LabelEncoder()\n",
    "    user_info[col] = user_info[col].fillna('NAN')\n",
    "    user_info[col] = lbe.fit_transform(user_info[col])\n",
    "\n",
    "print('user info')\n",
    "print(user_info.head())\n",
    "user_info.to_pickle('../data/user_info.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0          1              2  3  4   5  6    7\n",
      "0         1000014754  463510256  1624843756147  5  0  16  0    0\n",
      "1         1000014754  463852707  1624843756147  5  0  13  1   80\n",
      "2         1000014754  463067100  1624757147178  5  0  13  0    0\n",
      "3         1000014754  463625484  1624762446340  5  0  12  1  268\n",
      "4         1000014754  463625484  1624762446340  5  0  12  1   57\n",
      "...              ...        ...            ... .. ..  .. ..  ...\n",
      "81671128   999938860  463459430  1624885221612  2  2  20  0    0\n",
      "81671129   999938860  463930923  1624884995834  2  1  15  1    5\n",
      "81671130   999938860  463939123  1624885221612  2  2  23  0    0\n",
      "81671131   999938860  463270375  1624747290961  2  7  67  0    0\n",
      "81671132   999938860  463247124  1624747290961  2  7  69  0    0\n",
      "\n",
      "[81671133 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_info = pd.read_table('../data/train_info.txt',header=None)\n",
    "print(train_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_info = train_info.sample(frac=0.1)\n",
    "# print(train_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              userid      docid      timestamp  network  refresh  position  \\\n",
      "0         1000014754  463510256  1624843756147        5        0        16   \n",
      "1         1000014754  463852707  1624843756147        5        0        13   \n",
      "2         1000014754  463067100  1624757147178        5        0        13   \n",
      "3         1000014754  463625484  1624762446340        5        0        12   \n",
      "4         1000014754  463625484  1624762446340        5        0        12   \n",
      "...              ...        ...            ...      ...      ...       ...   \n",
      "81671128   999938860  463459430  1624885221612        2        2        20   \n",
      "81671129   999938860  463930923  1624884995834        2        1        15   \n",
      "81671130   999938860  463939123  1624885221612        2        2        23   \n",
      "81671131   999938860  463270375  1624747290961        2        7        67   \n",
      "81671132   999938860  463247124  1624747290961        2        7        69   \n",
      "\n",
      "          click  duration  \n",
      "0             0         0  \n",
      "1             1        80  \n",
      "2             0         0  \n",
      "3             1       268  \n",
      "4             1        57  \n",
      "...         ...       ...  \n",
      "81671128      0         0  \n",
      "81671129      1         5  \n",
      "81671130      0         0  \n",
      "81671131      0         0  \n",
      "81671132      0         0  \n",
      "\n",
      "[81671133 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "train_info.columns = ['userid','docid','timestamp','network','refresh','position','click','duration']\n",
    "print(train_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data\n",
      "       userid      docid      timestamp  network  refresh  position  click  \\\n",
      "0  1000014754  463510256  1624843756147        5        0        16      0   \n",
      "1  1000014754  463852707  1624843756147        5        0        13      1   \n",
      "2  1000014754  463067100  1624757147178        5        0        13      0   \n",
      "3  1000014754  463625484  1624762446340        5        0        12      1   \n",
      "4  1000014754  463625484  1624762446340        5        0        12      1   \n",
      "\n",
      "   duration                               dt        date  \n",
      "0         0 2021-06-28 09:29:16.147000+08:00  2021-06-28  \n",
      "1        80 2021-06-28 09:29:16.147000+08:00  2021-06-28  \n",
      "2         0 2021-06-27 09:25:47.178000+08:00  2021-06-27  \n",
      "3       268 2021-06-27 10:54:06.340000+08:00  2021-06-27  \n",
      "4        57 2021-06-27 10:54:06.340000+08:00  2021-06-27  \n"
     ]
    }
   ],
   "source": [
    "# train_info['dt'] = pd.to_datetime(train_info['timestamp'], utc=True, unit='ms').dt.tz_convert('Asia/Shanghai')\n",
    "# train_info['date'] = train_info['dt'].dt.date\n",
    "# train_info['date'] = train_info['date'].astype('str')\n",
    "print('train data')\n",
    "print(train_info.head())\n",
    "train_info.to_pickle('../data/train1.0.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bj2",
   "language": "python",
   "name": "bj2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
