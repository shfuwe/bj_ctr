{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import time, json, datetime\n",
    "from tqdm import tqdm\n",
    "import sys, getopt\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "device = torch.device('cuda:3') if torch.cuda.is_available() else torch.device('cpu')\n",
    "nono=[]\n",
    "# nono=['userid_duration_mean','userid_click_mean','docid_click_mean','refresh','keyword0_click_mean','refresh_duration_mean','refresh_click_count']\n",
    "pp='1.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class fn_cls(nn.Module):\n",
    "#     def __init__(self,device,nume_fea_size):\n",
    "#         super(fn_cls, self).__init__()\n",
    "#         self.model = AutoModel.from_pretrained(\"bert-base-chinese\")\n",
    "#         self.model.resize_token_embeddings(len(tokenizer))##############\n",
    "#         self.model.to(device)\n",
    "# #         self.dropout = nn.Dropout(0.5)\n",
    "#         self.l1 = nn.Linear(768, 1)\n",
    "#         self.l2 = nn.Linear(nume_fea_size, 1)\n",
    "#         self.l3 = nn.Linear(2, 1)\n",
    "#     def forward(self, nume_fea, input_ids, attention_mask):\n",
    "#         outputs = self.model(input_ids, attention_mask=attention_mask)\n",
    "# #         print(outputs[0])torch.Size([8, 100, 768])\n",
    "# #         print(outputs[1])torch.Size([8, 768])\n",
    "# #         print(outputs[0][:,0,:])torch.Size([8, 768])\n",
    "#         bert_cls = outputs[1]\n",
    "# #         x = self.dropout(x)\n",
    "#         x_bert = self.l1(bert_cls)\n",
    "    \n",
    "#         x_dense= self.l2(nume_fea)\n",
    "#         x=self.l3(torch.cat((x_bert,x_dense),1))\n",
    "        \n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "sigmoid=nn.Sigmoid()\n",
    "\n",
    "class fn_cls(nn.Module):\n",
    "    def __init__(self,device,nume_fea_size):\n",
    "        super(fn_cls, self).__init__()\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "        self.l1 = nn.Linear(128, 1)\n",
    "        self.l2 = nn.Linear(nume_fea_size, 1)\n",
    "        self.l3 = nn.Linear(2, 1)\n",
    "    def forward(self, nume_fea, emb):\n",
    "        x_title = self.l1(emb)\n",
    "        x_dense= self.l2(nume_fea)\n",
    "        x=self.l3(torch.cat((x_title,x_dense),1))\n",
    "        \n",
    "        return sigmoid(x_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def train_and_eval(model, train_loader, valid_loader, epochs, optimizer, loss_fcn, scheduler, device,best_auc,j,ii):\n",
    "#     import time\n",
    "#     for _ in range(epochs):\n",
    "#         \"\"\"训练部分\"\"\"\n",
    "        \n",
    "#         model.to(device)\n",
    "#         model.train()\n",
    "        \n",
    "#         print(\"Current lr : {}\".format(optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "#         write_log('Epoch: {}:{}'.format(j,ii))\n",
    "#         train_loss_sum = 0.0\n",
    "#         start_time = time.time()\n",
    "#         for idx, x in enumerate(train_loader):\n",
    "#             doc_id, nume_fea, label = x[0], x[1], x[2]\n",
    "#             doc_id=pd.DataFrame(doc_id,columns=['docid'])\n",
    "        \n",
    "#             doc_title=pd.merge(doc_id,title_,how='left',on='docid')\n",
    "#             input_ids=torch.LongTensor(np.stack(doc_title['input_ids'],axis=0))\n",
    "#             attention_mask=torch.LongTensor(np.stack(doc_title['attention_mask'],axis=0))\n",
    "            \n",
    "            \n",
    "#             nume_fea, input_ids, attention_mask, label = nume_fea.to(device), input_ids.to(device), attention_mask.to(device), label.float().to(device)\n",
    "# #             print(input_ids)\n",
    "#             pred = model(nume_fea, input_ids, attention_mask).view(-1)\n",
    "#             loss = loss_fcn(pred, label)\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             train_loss_sum += loss.cpu().item()\n",
    "#             if (idx + 1) % 50 == 0 or (idx + 1) == len(train_loader):\n",
    "#                 write_log(\"Epoch {:04d} | Step {:04d} / {} | Loss {:.4f} | Time {:.4f}\".format(\n",
    "#                     _ + 1, idx + 1, len(train_loader), train_loss_sum / (idx + 1), time.time() - start_time))\n",
    "#         scheduler.step()\n",
    "#         \"\"\"推断部分\"\"\"\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             valid_labels, valid_preds = [], []\n",
    "#             for idx, x in tqdm(enumerate(valid_loader)):\n",
    "#                 doc_id, nume_fea, label = x[0], x[1], x[2]\n",
    "#                 doc_id=pd.DataFrame(doc_id,columns=['docid'])\n",
    "                \n",
    "#                 doc_title=pd.merge(doc_id,title_,how='left',on='docid')\n",
    "#                 input_ids=torch.LongTensor(np.stack(doc_title['input_ids'],axis=0))\n",
    "#                 attention_mask=torch.LongTensor(np.stack(doc_title['attention_mask'],axis=0))\n",
    "                \n",
    "#                 nume_fea, input_ids, attention_mask = nume_fea.to(device), input_ids.to(device), attention_mask.to(device)\n",
    "#                 pred = model(nume_fea, input_ids, attention_mask).reshape(-1).data.cpu().numpy().tolist()\n",
    "#                 valid_preds.extend(pred)\n",
    "#                 valid_labels.extend(label.cpu().numpy().tolist())\n",
    "#         cur_auc = roc_auc_score(valid_labels, valid_preds)\n",
    "#         if cur_auc > best_auc:\n",
    "#             best_auc = cur_auc\n",
    "#             import time\n",
    "#             end=time.time()\n",
    "#             torch.save(model.state_dict(), \"../../data/wj/bert_best/\"+pp+\"/bert_best_\"+str(round(best_auc,4))+\"_\"+str(j)+\"_\"+str(ii)+\"_\"+str(time.strftime('%m_%d_%H_%M_%S'))+\".pth\")\n",
    "#         write_log('Current AUC: %.6f, Best AUC: %.6f\\n' % (cur_auc, best_auc))\n",
    "#     return best_auc\n",
    "\n",
    "def train_and_eval(model, train_loader, valid_loader, epochs, optimizer, loss_fcn, scheduler, device,best_auc,j,ii):\n",
    "    import time\n",
    "    for _ in range(epochs):\n",
    "        \"\"\"训练部分\"\"\"\n",
    "        \n",
    "        model.to(device)\n",
    "        model.train()\n",
    "        \n",
    "        print(\"Current lr : {}\".format(optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        write_log('Epoch: {}:{}'.format(j,ii))\n",
    "        train_loss_sum = 0.0\n",
    "        start_time = time.time()\n",
    "        for idx, x in enumerate(train_loader):\n",
    "            doc_id, nume_fea, label = x[0], x[1], x[2]\n",
    "            doc_id=pd.DataFrame(doc_id,columns=['docid'])\n",
    "            doc_title=pd.merge(doc_id,title_,how='left',on='docid')\n",
    "            title_0=torch.FloatTensor(np.stack(doc_title['title_'],axis=0))\n",
    "            \n",
    "            nume_fea, title_0, label = nume_fea.to(device), title_0.to(device), label.float().to(device)\n",
    "#             print(input_ids)\n",
    "            pred = model(nume_fea, title_0).view(-1)\n",
    "            loss = loss_fcn(pred, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss_sum += loss.cpu().item()\n",
    "            if (idx + 1) % 50 == 0 or (idx + 1) == len(train_loader):\n",
    "                write_log(\"Epoch {:04d} | Step {:04d} / {} | Loss {:.4f} | Time {:.4f}\".format(\n",
    "                    _ + 1, idx + 1, len(train_loader), train_loss_sum / (idx + 1), time.time() - start_time))\n",
    "        scheduler.step()\n",
    "        \"\"\"推断部分\"\"\"\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_labels, valid_preds = [], []\n",
    "            for idx, x in tqdm(enumerate(valid_loader)):\n",
    "                doc_id, nume_fea, label = x[0], x[1], x[2]\n",
    "                doc_id=pd.DataFrame(doc_id,columns=['docid'])\n",
    "                doc_title=pd.merge(doc_id,title_,how='left',on='docid')\n",
    "                title_0=torch.FloatTensor(np.stack(doc_title['title_'],axis=0))\n",
    "                \n",
    "                nume_fea, title_0 = nume_fea.to(device), title_0.to(device)\n",
    "                pred = model(nume_fea, title_0).reshape(-1).data.cpu().numpy().tolist()\n",
    "                valid_preds.extend(pred)\n",
    "                valid_labels.extend(label.cpu().numpy().tolist())\n",
    "        cur_auc = roc_auc_score(valid_labels, valid_preds)\n",
    "        if cur_auc > best_auc:\n",
    "            best_auc = cur_auc\n",
    "            import time\n",
    "            end=time.time()\n",
    "            torch.save(model.state_dict(), \"../../data/wj/bert_best/\"+pp+\"/bert_best_\"+str(round(best_auc,4))+\"_\"+str(j)+\"_\"+str(ii)+\"_\"+str(time.strftime('%m_%d_%H_%M_%S'))+\".pth\")\n",
    "        write_log('Current AUC: %.6f, Best AUC: %.6f\\n' % (cur_auc, best_auc))\n",
    "    return best_auc\n",
    "\n",
    "\n",
    "import pytz\n",
    "import datetime\n",
    "tz = pytz.timezone('Asia/Shanghai')\n",
    "\n",
    "# 定义日志（data文件夹下，同级目录新建一个data文件夹）\n",
    "def write_log(w):\n",
    "    file_name = '../../data/wj/bert_best/'+pp+'/' + datetime.date.today().strftime('%m%d') + \"_{}.log\".format(\"bert\")\n",
    "    t0 = datetime.datetime.now(tz).strftime('%H:%M:%S')\n",
    "    info = \"{} : {}\".format(t0, w)\n",
    "    print(info)\n",
    "    with open(file_name, 'a') as f:\n",
    "        f.write(info + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 46\n"
     ]
    }
   ],
   "source": [
    "doc_feat = pd.read_pickle('../../data/wj/doc.pkl')\n",
    "user_feat = pd.read_pickle('../../data/wj/user.pkl')\n",
    "\n",
    "sparse_features = ['userid', 'docid', 'network', 'hour', 'device', 'os', 'province',\n",
    "                   'city', 'age', 'gender', 'category1st', 'category2nd',\n",
    "                   'pub_date', 'keyword0', 'keyword1', 'keyword2', 'keyword3', 'keyword4']\n",
    "\n",
    "dense_features0 = ['refresh', 'picnum',\n",
    "                  'userid_click_mean','userid_click_count' ,'userid_duration_mean' ,'userid_picnum_mean',\n",
    "                   'docid_click_mean','docid_click_count','docid_duration_mean','docid_picnum_mean',\n",
    "                    'category1st_click_mean','category1st_click_count','category1st_duration_mean','category1st_picnum_mean',\n",
    "                    'category2nd_click_mean','category2nd_click_count','category2nd_duration_mean','category2nd_picnum_mean',\n",
    "                    'keyword0_click_mean','keyword0_click_count','keyword0_duration_mean','keyword0_picnum_mean',\n",
    "                 'network_click_mean', 'network_click_count', 'network_duration_mean', \n",
    "                  'refresh_click_mean', 'refresh_click_count', 'refresh_duration_mean',\n",
    "                  'device_click_mean', 'device_click_count', 'device_duration_mean', \n",
    "                  'os_click_mean', 'os_click_count', 'os_duration_mean', \n",
    "                  'province_click_mean', 'province_click_count', 'province_duration_mean', \n",
    "                  'city_click_mean', 'city_click_count', 'city_duration_mean', \n",
    "                  'age_click_mean', 'age_click_count', 'age_duration_mean', \n",
    "                  'gender_click_mean', 'gender_click_count', 'gender_duration_mean'\n",
    "                 ]\n",
    "\n",
    "dense_features=[]\n",
    "for i in dense_features0:\n",
    "    if i not in nono:\n",
    "        dense_features.append(i)\n",
    "print(len(dense_features0),len(dense_features))\n",
    "\n",
    "cate_fea_nuniqs = []\n",
    "cate_fea_nuniqs.append(user_feat['userid'].nunique() + 1)\n",
    "cate_fea_nuniqs.append(doc_feat['docid'].nunique() + 1)\n",
    "cate_fea_nuniqs.append(6)  # network\n",
    "cate_fea_nuniqs.append(13)  # hour\n",
    "cate_fea_nuniqs.append(user_feat['device'].nunique())\n",
    "cate_fea_nuniqs.append(user_feat['os'].nunique())\n",
    "cate_fea_nuniqs.append(user_feat['province'].nunique())\n",
    "cate_fea_nuniqs.append(user_feat['city'].nunique())\n",
    "cate_fea_nuniqs.append(user_feat['age'].nunique())\n",
    "cate_fea_nuniqs.append(user_feat['gender'].nunique())\n",
    "cate_fea_nuniqs.append(doc_feat['category1st'].nunique())\n",
    "cate_fea_nuniqs.append(doc_feat['category2nd'].nunique())\n",
    "cate_fea_nuniqs.append(doc_feat['pub_date'].nunique())\n",
    "keyword_nunique = max(doc_feat['keyword0'].max(), doc_feat['keyword1'].max(), doc_feat['keyword2'].max()\n",
    "                      , doc_feat['keyword3'].max(), doc_feat['keyword4'].max()) + 1\n",
    "cate_fea_nuniqs.append(keyword_nunique)\n",
    "cate_fea_nuniqs.append(keyword_nunique)\n",
    "cate_fea_nuniqs.append(keyword_nunique)\n",
    "cate_fea_nuniqs.append(keyword_nunique)\n",
    "cate_fea_nuniqs.append(keyword_nunique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>title_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[-0.24676482, -0.23273347, 0.2768831, 0.895596...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[-0.73832685, -0.43277335, 0.51343787, -0.0298...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[-0.14395653, -0.010464772, 0.5642408, -0.1496...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[-0.4864518, -0.14376818, 0.6203714, -0.332095...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[-0.26730365, -0.23369296, 0.58975637, 0.31177...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347461</th>\n",
       "      <td>347462</td>\n",
       "      <td>[-0.34230515, -0.21498469, 0.5045544, -0.01475...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347462</th>\n",
       "      <td>347463</td>\n",
       "      <td>[0.061109103, -0.46459514, 0.41572598, 0.42648...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347463</th>\n",
       "      <td>347464</td>\n",
       "      <td>[0.13422157, -0.6389209, 0.40489706, 0.3870600...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347464</th>\n",
       "      <td>347465</td>\n",
       "      <td>[-0.3166948, -0.4144859, 0.63666326, 0.1945693...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347465</th>\n",
       "      <td>347466</td>\n",
       "      <td>[-0.59561664, -0.19312923, 1.4018544, -0.20026...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>347466 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         docid                                             title_\n",
       "0            1  [-0.24676482, -0.23273347, 0.2768831, 0.895596...\n",
       "1            2  [-0.73832685, -0.43277335, 0.51343787, -0.0298...\n",
       "2            3  [-0.14395653, -0.010464772, 0.5642408, -0.1496...\n",
       "3            4  [-0.4864518, -0.14376818, 0.6203714, -0.332095...\n",
       "4            5  [-0.26730365, -0.23369296, 0.58975637, 0.31177...\n",
       "...        ...                                                ...\n",
       "347461  347462  [-0.34230515, -0.21498469, 0.5045544, -0.01475...\n",
       "347462  347463  [0.061109103, -0.46459514, 0.41572598, 0.42648...\n",
       "347463  347464  [0.13422157, -0.6389209, 0.40489706, 0.3870600...\n",
       "347464  347465  [-0.3166948, -0.4144859, 0.63666326, 0.1945693...\n",
       "347465  347466  [-0.59561664, -0.19312923, 1.4018544, -0.20026...\n",
       "\n",
       "[347466 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "title_=pd.read_pickle('../../data/wj/title_embedding.pkl')\n",
    "del title_['title']\n",
    "title_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# title_=pd.read_csv('../../data/wj/doc_title.csv')\n",
    "# text=title_['title'].tolist()\n",
    "# for i in range(len(text)):\n",
    "#     if not isinstance(text[i], str):\n",
    "#         print(text[i])\n",
    "#         text[i]=''\n",
    "\n",
    "\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "# # added_token=['##char##']\n",
    "# # tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\",additional_special_tokens=added_token)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "# text2id=tokenizer(text, max_length=100, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "# nput_ids=text2id[\"input_ids\"].tolist()\n",
    "# attention_mask=text2id[\"attention_mask\"].tolist()\n",
    "# title_['input_ids']=nput_ids\n",
    "# title_['attention_mask']=attention_mask\n",
    "\n",
    "# title_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = fn_cls(device,nume_fea_size=len(dense_features))\n",
    "\n",
    "loss_fcn = nn.MSELoss()\n",
    "loss_fcn = loss_fcn.to(device)\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.8)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.8)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "\n",
    "# len_=81671133\n",
    "# best_auc=0\n",
    "# for j in range(5):\n",
    "#     ii=-1\n",
    "#     for i in range(0,len_,round(len_/10)):\n",
    "#         ii+=1\n",
    "#         right=i+round(len_/10)\n",
    "#         if right>=len_:\n",
    "#             break\n",
    "#         print(i,right)\n",
    "#         df_train_user_doc=pd.read_pickle('../../data/wj/df_train_user_doc_0_1_'+str(i)+'_'+str(right)+'_64.pkl')\n",
    "# #         df_train_user_doc=pd.merge(df_train_user_doc,title_,how='left',on='docid')\n",
    "        \n",
    "#         train, valid = train_test_split(df_train_user_doc, test_size=0.25, random_state=2021)\n",
    "# #         train_loader，valid_loader\n",
    "#         train_dataset = Data.TensorDataset(torch.LongTensor(np.stack(train['docid'].values,axis=0)),\n",
    "#                                            torch.FloatTensor(train[dense_features].values),\n",
    "#                                            torch.FloatTensor(train['click'].values), )\n",
    "#         train_loader = Data.DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
    "        \n",
    "#         valid_dataset = Data.TensorDataset(torch.LongTensor(np.stack(valid['docid'].values,axis=0)),\n",
    "#                                            torch.FloatTensor(valid[dense_features].values),\n",
    "#                                            torch.FloatTensor(valid['click'].values))\n",
    "#         valid_loader = Data.DataLoader(dataset=valid_dataset, batch_size=16, shuffle=False)\n",
    "# #         train\n",
    "#         print('train')\n",
    "#         epoch_=1\n",
    "#         best_auc=train_and_eval(model, train_loader, valid_loader, epoch_, optimizer, loss_fcn, scheduler, device,best_auc,j,ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8167113\n",
      "train\n",
      "Current lr : 0.005\n",
      "20:24:43 : Epoch: 0:0\n",
      "20:25:00 : Epoch 0001 | Step 0050 / 748 | Loss 0.1364 | Time 17.6178\n",
      "20:25:17 : Epoch 0001 | Step 0100 / 748 | Loss 0.1291 | Time 34.6289\n",
      "20:25:35 : Epoch 0001 | Step 0150 / 748 | Loss 0.1262 | Time 52.2068\n",
      "20:25:52 : Epoch 0001 | Step 0200 / 748 | Loss 0.1247 | Time 69.6732\n",
      "20:26:10 : Epoch 0001 | Step 0250 / 748 | Loss 0.1236 | Time 86.8692\n",
      "20:26:27 : Epoch 0001 | Step 0300 / 748 | Loss 0.1229 | Time 104.2601\n",
      "20:26:45 : Epoch 0001 | Step 0350 / 748 | Loss 0.1223 | Time 121.8563\n",
      "20:27:02 : Epoch 0001 | Step 0400 / 748 | Loss 0.1219 | Time 138.9626\n",
      "20:27:19 : Epoch 0001 | Step 0450 / 748 | Loss 0.1215 | Time 156.4903\n",
      "20:27:37 : Epoch 0001 | Step 0500 / 748 | Loss 0.1212 | Time 173.9603\n",
      "20:27:54 : Epoch 0001 | Step 0550 / 748 | Loss 0.1209 | Time 191.2479\n",
      "20:28:11 : Epoch 0001 | Step 0600 / 748 | Loss 0.1206 | Time 208.7107\n",
      "20:28:29 : Epoch 0001 | Step 0650 / 748 | Loss 0.1204 | Time 226.1427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:25,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:30:30 : Current AUC: 0.704431, Best AUC: 0.704431\n",
      "\n",
      "8167113 16334226\n",
      "train\n",
      "Current lr : 0.004\n",
      "20:31:01 : Epoch: 0:1\n",
      "20:31:19 : Epoch 0001 | Step 0050 / 748 | Loss 0.1149 | Time 18.4212\n",
      "20:31:38 : Epoch 0001 | Step 0100 / 748 | Loss 0.1148 | Time 36.7855\n",
      "20:31:55 : Epoch 0001 | Step 0150 / 748 | Loss 0.1146 | Time 54.5719\n",
      "20:32:14 : Epoch 0001 | Step 0200 / 748 | Loss 0.1144 | Time 72.8712\n",
      "20:32:32 : Epoch 0001 | Step 0250 / 748 | Loss 0.1143 | Time 91.3567\n",
      "20:32:50 : Epoch 0001 | Step 0300 / 748 | Loss 0.1140 | Time 109.2642\n",
      "20:33:08 : Epoch 0001 | Step 0350 / 748 | Loss 0.1136 | Time 127.4419\n",
      "20:33:26 : Epoch 0001 | Step 0400 / 748 | Loss 0.1134 | Time 145.4930\n",
      "20:33:45 : Epoch 0001 | Step 0450 / 748 | Loss 0.1132 | Time 163.8511\n",
      "20:34:03 : Epoch 0001 | Step 0500 / 748 | Loss 0.1130 | Time 182.0137\n",
      "20:34:21 : Epoch 0001 | Step 0550 / 748 | Loss 0.1127 | Time 200.0541\n",
      "20:34:39 : Epoch 0001 | Step 0600 / 748 | Loss 0.1125 | Time 218.4814\n",
      "20:34:57 : Epoch 0001 | Step 0650 / 748 | Loss 0.1124 | Time 236.4009\n",
      "20:35:15 : Epoch 0001 | Step 0700 / 748 | Loss 0.1123 | Time 254.2180\n",
      "20:35:32 : Epoch 0001 | Step 0748 / 748 | Loss 0.1122 | Time 271.3497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:26,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:37:00 : Current AUC: 0.749229, Best AUC: 0.749229\n",
      "\n",
      "16334226 24501339\n",
      "train\n",
      "Current lr : 0.0032\n",
      "20:37:31 : Epoch: 0:2\n",
      "20:37:50 : Epoch 0001 | Step 0050 / 748 | Loss 0.1106 | Time 19.0055\n",
      "20:38:07 : Epoch 0001 | Step 0100 / 748 | Loss 0.1104 | Time 36.9457\n",
      "20:38:26 : Epoch 0001 | Step 0150 / 748 | Loss 0.1104 | Time 55.0159\n",
      "20:38:44 : Epoch 0001 | Step 0200 / 748 | Loss 0.1104 | Time 73.0008\n",
      "20:39:01 : Epoch 0001 | Step 0250 / 748 | Loss 0.1102 | Time 90.9613\n",
      "20:39:20 : Epoch 0001 | Step 0300 / 748 | Loss 0.1101 | Time 109.1303\n",
      "20:39:38 : Epoch 0001 | Step 0350 / 748 | Loss 0.1101 | Time 127.4278\n",
      "20:39:56 : Epoch 0001 | Step 0400 / 748 | Loss 0.1102 | Time 145.4660\n",
      "20:40:14 : Epoch 0001 | Step 0450 / 748 | Loss 0.1102 | Time 163.2189\n",
      "20:40:32 : Epoch 0001 | Step 0500 / 748 | Loss 0.1101 | Time 181.5004\n",
      "20:40:50 : Epoch 0001 | Step 0550 / 748 | Loss 0.1101 | Time 199.7007\n",
      "20:41:08 : Epoch 0001 | Step 0600 / 748 | Loss 0.1101 | Time 217.5842\n",
      "20:41:27 : Epoch 0001 | Step 0650 / 748 | Loss 0.1100 | Time 236.1387\n",
      "20:41:45 : Epoch 0001 | Step 0700 / 748 | Loss 0.1100 | Time 254.2261\n",
      "20:42:02 : Epoch 0001 | Step 0748 / 748 | Loss 0.1099 | Time 271.0651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:27,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:43:31 : Current AUC: 0.755873, Best AUC: 0.755873\n",
      "\n",
      "24501339 32668452\n",
      "train\n",
      "Current lr : 0.00256\n",
      "20:44:01 : Epoch: 0:3\n",
      "20:44:20 : Epoch 0001 | Step 0050 / 748 | Loss 0.1097 | Time 18.8320\n",
      "20:44:38 : Epoch 0001 | Step 0100 / 748 | Loss 0.1098 | Time 37.1070\n",
      "20:44:56 : Epoch 0001 | Step 0150 / 748 | Loss 0.1097 | Time 55.1216\n",
      "20:45:14 : Epoch 0001 | Step 0200 / 748 | Loss 0.1097 | Time 73.0194\n",
      "20:45:32 : Epoch 0001 | Step 0250 / 748 | Loss 0.1096 | Time 90.9898\n",
      "20:45:50 : Epoch 0001 | Step 0300 / 748 | Loss 0.1095 | Time 109.2915\n",
      "20:46:08 : Epoch 0001 | Step 0350 / 748 | Loss 0.1096 | Time 127.3281\n",
      "20:46:26 : Epoch 0001 | Step 0400 / 748 | Loss 0.1096 | Time 145.2649\n",
      "20:46:44 : Epoch 0001 | Step 0450 / 748 | Loss 0.1095 | Time 163.4464\n",
      "20:47:03 : Epoch 0001 | Step 0500 / 748 | Loss 0.1095 | Time 181.4847\n",
      "20:47:21 : Epoch 0001 | Step 0550 / 748 | Loss 0.1095 | Time 199.6159\n",
      "20:47:39 : Epoch 0001 | Step 0600 / 748 | Loss 0.1095 | Time 217.5548\n",
      "20:47:57 : Epoch 0001 | Step 0650 / 748 | Loss 0.1094 | Time 235.9522\n",
      "20:48:15 : Epoch 0001 | Step 0700 / 748 | Loss 0.1095 | Time 254.2751\n",
      "20:48:32 : Epoch 0001 | Step 0748 / 748 | Loss 0.1095 | Time 271.3699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:27,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:50:01 : Current AUC: 0.758045, Best AUC: 0.758045\n",
      "\n",
      "32668452 40835565\n",
      "train\n",
      "Current lr : 0.0020480000000000003\n",
      "20:50:32 : Epoch: 0:4\n",
      "20:50:50 : Epoch 0001 | Step 0050 / 748 | Loss 0.1094 | Time 18.5400\n",
      "20:51:08 : Epoch 0001 | Step 0100 / 748 | Loss 0.1094 | Time 36.3550\n",
      "20:51:26 : Epoch 0001 | Step 0150 / 748 | Loss 0.1091 | Time 54.3325\n",
      "20:51:44 : Epoch 0001 | Step 0200 / 748 | Loss 0.1092 | Time 72.0636\n",
      "20:52:02 : Epoch 0001 | Step 0250 / 748 | Loss 0.1092 | Time 90.2144\n",
      "20:52:20 : Epoch 0001 | Step 0300 / 748 | Loss 0.1092 | Time 108.0671\n",
      "20:52:37 : Epoch 0001 | Step 0350 / 748 | Loss 0.1091 | Time 125.7904\n",
      "20:52:56 : Epoch 0001 | Step 0400 / 748 | Loss 0.1091 | Time 144.1859\n",
      "20:53:14 : Epoch 0001 | Step 0450 / 748 | Loss 0.1091 | Time 162.0318\n",
      "20:53:32 : Epoch 0001 | Step 0500 / 748 | Loss 0.1091 | Time 180.0024\n",
      "20:53:50 : Epoch 0001 | Step 0550 / 748 | Loss 0.1092 | Time 198.3957\n",
      "20:54:08 : Epoch 0001 | Step 0600 / 748 | Loss 0.1092 | Time 216.4922\n",
      "20:54:26 : Epoch 0001 | Step 0650 / 748 | Loss 0.1092 | Time 234.4912\n",
      "20:54:44 : Epoch 0001 | Step 0700 / 748 | Loss 0.1092 | Time 252.3736\n",
      "20:55:01 : Epoch 0001 | Step 0748 / 748 | Loss 0.1092 | Time 269.4857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:27,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:56:30 : Current AUC: 0.759006, Best AUC: 0.759006\n",
      "\n",
      "40835565 49002678\n",
      "train\n",
      "Current lr : 0.0016384000000000004\n",
      "20:57:00 : Epoch: 0:5\n",
      "20:57:19 : Epoch 0001 | Step 0050 / 748 | Loss 0.1094 | Time 18.8235\n",
      "20:57:37 : Epoch 0001 | Step 0100 / 748 | Loss 0.1095 | Time 36.5838\n",
      "20:57:54 : Epoch 0001 | Step 0150 / 748 | Loss 0.1091 | Time 54.3780\n",
      "20:58:12 : Epoch 0001 | Step 0200 / 748 | Loss 0.1093 | Time 72.3964\n",
      "20:58:30 : Epoch 0001 | Step 0250 / 748 | Loss 0.1093 | Time 90.2887\n",
      "20:58:48 : Epoch 0001 | Step 0300 / 748 | Loss 0.1092 | Time 108.2106\n",
      "20:59:06 : Epoch 0001 | Step 0350 / 748 | Loss 0.1092 | Time 126.3119\n",
      "20:59:24 : Epoch 0001 | Step 0400 / 748 | Loss 0.1093 | Time 144.1043\n",
      "20:59:42 : Epoch 0001 | Step 0450 / 748 | Loss 0.1093 | Time 162.4937\n",
      "21:00:00 : Epoch 0001 | Step 0500 / 748 | Loss 0.1093 | Time 180.1521\n",
      "21:00:18 : Epoch 0001 | Step 0550 / 748 | Loss 0.1093 | Time 198.1252\n",
      "21:00:36 : Epoch 0001 | Step 0600 / 748 | Loss 0.1092 | Time 215.6914\n",
      "21:00:54 : Epoch 0001 | Step 0650 / 748 | Loss 0.1093 | Time 234.0085\n",
      "21:01:12 : Epoch 0001 | Step 0700 / 748 | Loss 0.1093 | Time 251.8733\n",
      "21:01:29 : Epoch 0001 | Step 0748 / 748 | Loss 0.1093 | Time 269.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:25,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:02:56 : Current AUC: 0.757010, Best AUC: 0.759006\n",
      "\n",
      "49002678 57169791\n",
      "train\n",
      "Current lr : 0.0013107200000000005\n",
      "21:04:03 : Epoch: 0:6\n",
      "21:04:22 : Epoch 0001 | Step 0050 / 748 | Loss 0.1092 | Time 18.8086\n",
      "21:04:40 : Epoch 0001 | Step 0100 / 748 | Loss 0.1093 | Time 37.0676\n",
      "21:04:58 : Epoch 0001 | Step 0150 / 748 | Loss 0.1093 | Time 54.8954\n",
      "21:05:16 : Epoch 0001 | Step 0200 / 748 | Loss 0.1093 | Time 73.2643\n",
      "21:05:34 : Epoch 0001 | Step 0250 / 748 | Loss 0.1094 | Time 91.1971\n",
      "21:05:53 : Epoch 0001 | Step 0300 / 748 | Loss 0.1094 | Time 109.5958\n",
      "21:06:11 : Epoch 0001 | Step 0350 / 748 | Loss 0.1094 | Time 127.7765\n",
      "21:06:29 : Epoch 0001 | Step 0400 / 748 | Loss 0.1093 | Time 145.8595\n",
      "21:06:48 : Epoch 0001 | Step 0450 / 748 | Loss 0.1092 | Time 164.3760\n",
      "21:07:06 : Epoch 0001 | Step 0500 / 748 | Loss 0.1093 | Time 182.5394\n",
      "21:07:24 : Epoch 0001 | Step 0550 / 748 | Loss 0.1093 | Time 200.4160\n",
      "21:07:42 : Epoch 0001 | Step 0600 / 748 | Loss 0.1093 | Time 218.3983\n",
      "21:08:00 : Epoch 0001 | Step 0650 / 748 | Loss 0.1093 | Time 236.7355\n",
      "21:08:18 : Epoch 0001 | Step 0700 / 748 | Loss 0.1093 | Time 255.0756\n",
      "21:08:36 : Epoch 0001 | Step 0748 / 748 | Loss 0.1093 | Time 272.6331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:27,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:10:05 : Current AUC: 0.759360, Best AUC: 0.759360\n",
      "\n",
      "57169791 65336904\n",
      "train\n",
      "Current lr : 0.0010485760000000005\n",
      "21:10:58 : Epoch: 0:7\n",
      "21:11:16 : Epoch 0001 | Step 0050 / 748 | Loss 0.1092 | Time 18.4005\n",
      "21:11:35 : Epoch 0001 | Step 0100 / 748 | Loss 0.1090 | Time 36.8482\n",
      "21:11:53 : Epoch 0001 | Step 0150 / 748 | Loss 0.1089 | Time 54.8824\n",
      "21:12:11 : Epoch 0001 | Step 0200 / 748 | Loss 0.1090 | Time 73.2179\n",
      "21:12:30 : Epoch 0001 | Step 0250 / 748 | Loss 0.1091 | Time 91.5995\n",
      "21:12:48 : Epoch 0001 | Step 0300 / 748 | Loss 0.1092 | Time 109.9627\n",
      "21:13:06 : Epoch 0001 | Step 0350 / 748 | Loss 0.1092 | Time 128.2648\n",
      "21:13:25 : Epoch 0001 | Step 0400 / 748 | Loss 0.1093 | Time 146.9157\n",
      "21:13:43 : Epoch 0001 | Step 0450 / 748 | Loss 0.1092 | Time 165.0713\n",
      "21:14:01 : Epoch 0001 | Step 0500 / 748 | Loss 0.1092 | Time 183.4252\n",
      "21:14:20 : Epoch 0001 | Step 0550 / 748 | Loss 0.1092 | Time 201.6313\n",
      "21:14:38 : Epoch 0001 | Step 0600 / 748 | Loss 0.1092 | Time 220.2117\n",
      "21:14:57 : Epoch 0001 | Step 0650 / 748 | Loss 0.1092 | Time 239.4279\n",
      "21:15:16 : Epoch 0001 | Step 0700 / 748 | Loss 0.1092 | Time 258.0401\n",
      "21:15:34 : Epoch 0001 | Step 0748 / 748 | Loss 0.1092 | Time 276.1294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:27,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:17:03 : Current AUC: 0.757452, Best AUC: 0.759360\n",
      "\n",
      "65336904 73504017\n",
      "train\n",
      "Current lr : 0.0008388608000000005\n",
      "21:18:07 : Epoch: 0:8\n",
      "21:18:26 : Epoch 0001 | Step 0050 / 748 | Loss 0.1088 | Time 19.2523\n",
      "21:18:44 : Epoch 0001 | Step 0100 / 748 | Loss 0.1091 | Time 37.4503\n",
      "21:19:03 : Epoch 0001 | Step 0150 / 748 | Loss 0.1091 | Time 55.6787\n",
      "21:19:21 : Epoch 0001 | Step 0200 / 748 | Loss 0.1092 | Time 73.6455\n",
      "21:19:39 : Epoch 0001 | Step 0250 / 748 | Loss 0.1093 | Time 91.9140\n",
      "21:19:57 : Epoch 0001 | Step 0300 / 748 | Loss 0.1092 | Time 110.3000\n",
      "21:20:15 : Epoch 0001 | Step 0350 / 748 | Loss 0.1092 | Time 128.4766\n",
      "21:20:34 : Epoch 0001 | Step 0400 / 748 | Loss 0.1092 | Time 146.9461\n",
      "21:20:52 : Epoch 0001 | Step 0450 / 748 | Loss 0.1092 | Time 164.7537\n",
      "21:21:10 : Epoch 0001 | Step 0500 / 748 | Loss 0.1093 | Time 183.0649\n",
      "21:21:28 : Epoch 0001 | Step 0550 / 748 | Loss 0.1093 | Time 201.2172\n",
      "21:21:47 : Epoch 0001 | Step 0600 / 748 | Loss 0.1093 | Time 219.8161\n",
      "21:22:05 : Epoch 0001 | Step 0650 / 748 | Loss 0.1093 | Time 237.8740\n",
      "21:22:23 : Epoch 0001 | Step 0700 / 748 | Loss 0.1093 | Time 256.2202\n",
      "21:22:41 : Epoch 0001 | Step 0748 / 748 | Loss 0.1093 | Time 273.9794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:28,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:24:11 : Current AUC: 0.759838, Best AUC: 0.759838\n",
      "\n",
      "73504017 81671130\n",
      "train\n",
      "Current lr : 0.0006710886400000004\n",
      "21:24:47 : Epoch: 0:9\n",
      "21:25:05 : Epoch 0001 | Step 0050 / 748 | Loss 0.1086 | Time 18.4275\n",
      "21:25:24 : Epoch 0001 | Step 0100 / 748 | Loss 0.1087 | Time 36.4559\n",
      "21:25:41 : Epoch 0001 | Step 0150 / 748 | Loss 0.1089 | Time 54.2394\n",
      "21:26:00 : Epoch 0001 | Step 0200 / 748 | Loss 0.1091 | Time 72.9354\n",
      "21:26:18 : Epoch 0001 | Step 0250 / 748 | Loss 0.1091 | Time 91.2539\n",
      "21:26:36 : Epoch 0001 | Step 0300 / 748 | Loss 0.1090 | Time 109.0069\n",
      "21:26:54 : Epoch 0001 | Step 0350 / 748 | Loss 0.1090 | Time 127.1567\n",
      "21:27:12 : Epoch 0001 | Step 0400 / 748 | Loss 0.1091 | Time 145.0584\n",
      "21:27:30 : Epoch 0001 | Step 0450 / 748 | Loss 0.1091 | Time 163.1029\n",
      "21:27:48 : Epoch 0001 | Step 0500 / 748 | Loss 0.1091 | Time 181.2208\n",
      "21:28:06 : Epoch 0001 | Step 0550 / 748 | Loss 0.1091 | Time 199.1449\n",
      "21:28:24 : Epoch 0001 | Step 0600 / 748 | Loss 0.1091 | Time 217.2030\n",
      "21:28:43 : Epoch 0001 | Step 0650 / 748 | Loss 0.1092 | Time 235.9239\n",
      "21:29:01 : Epoch 0001 | Step 0700 / 748 | Loss 0.1091 | Time 254.2441\n",
      "21:29:19 : Epoch 0001 | Step 0748 / 748 | Loss 0.1091 | Time 271.5028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:26,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:30:47 : Current AUC: 0.757495, Best AUC: 0.759838\n",
      "\n",
      "0 8167113\n",
      "train\n",
      "Current lr : 0.0005368709120000003\n",
      "21:31:17 : Epoch: 1:0\n",
      "21:31:36 : Epoch 0001 | Step 0050 / 748 | Loss 0.1089 | Time 18.5334\n",
      "21:31:54 : Epoch 0001 | Step 0100 / 748 | Loss 0.1091 | Time 36.2331\n",
      "21:32:12 : Epoch 0001 | Step 0150 / 748 | Loss 0.1092 | Time 54.6260\n",
      "21:32:30 : Epoch 0001 | Step 0200 / 748 | Loss 0.1092 | Time 72.6963\n",
      "21:32:48 : Epoch 0001 | Step 0250 / 748 | Loss 0.1091 | Time 90.9388\n",
      "21:33:06 : Epoch 0001 | Step 0300 / 748 | Loss 0.1092 | Time 109.1255\n",
      "21:33:25 : Epoch 0001 | Step 0350 / 748 | Loss 0.1091 | Time 127.3853\n",
      "21:33:43 : Epoch 0001 | Step 0400 / 748 | Loss 0.1091 | Time 145.6325\n",
      "21:34:02 : Epoch 0001 | Step 0450 / 748 | Loss 0.1091 | Time 164.4184\n",
      "21:34:20 : Epoch 0001 | Step 0500 / 748 | Loss 0.1090 | Time 182.8491\n",
      "21:34:39 : Epoch 0001 | Step 0550 / 748 | Loss 0.1090 | Time 201.3179\n",
      "21:34:57 : Epoch 0001 | Step 0600 / 748 | Loss 0.1090 | Time 219.5586\n",
      "21:35:15 : Epoch 0001 | Step 0650 / 748 | Loss 0.1090 | Time 237.7312\n",
      "21:35:33 : Epoch 0001 | Step 0700 / 748 | Loss 0.1090 | Time 255.9238\n",
      "21:35:52 : Epoch 0001 | Step 0748 / 748 | Loss 0.1090 | Time 274.9206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:28,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:37:22 : Current AUC: 0.758885, Best AUC: 0.759838\n",
      "\n",
      "8167113 16334226\n",
      "train\n",
      "Current lr : 0.0004294967296000003\n",
      "21:37:53 : Epoch: 1:1\n",
      "21:38:12 : Epoch 0001 | Step 0050 / 748 | Loss 0.1095 | Time 19.0003\n",
      "21:38:30 : Epoch 0001 | Step 0100 / 748 | Loss 0.1094 | Time 36.9886\n",
      "21:38:49 : Epoch 0001 | Step 0150 / 748 | Loss 0.1092 | Time 55.2421\n",
      "21:39:07 : Epoch 0001 | Step 0200 / 748 | Loss 0.1091 | Time 73.2345\n",
      "21:39:25 : Epoch 0001 | Step 0250 / 748 | Loss 0.1091 | Time 91.9091\n",
      "21:39:44 : Epoch 0001 | Step 0300 / 748 | Loss 0.1090 | Time 110.6552\n",
      "21:40:02 : Epoch 0001 | Step 0350 / 748 | Loss 0.1090 | Time 128.5611\n",
      "21:40:20 : Epoch 0001 | Step 0400 / 748 | Loss 0.1089 | Time 147.0556\n",
      "21:40:39 : Epoch 0001 | Step 0450 / 748 | Loss 0.1090 | Time 165.4283\n",
      "21:40:57 : Epoch 0001 | Step 0500 / 748 | Loss 0.1090 | Time 183.9974\n",
      "21:41:16 : Epoch 0001 | Step 0550 / 748 | Loss 0.1090 | Time 202.5957\n",
      "21:41:34 : Epoch 0001 | Step 0600 / 748 | Loss 0.1090 | Time 220.7466\n",
      "21:41:52 : Epoch 0001 | Step 0650 / 748 | Loss 0.1090 | Time 238.8138\n",
      "21:42:11 : Epoch 0001 | Step 0700 / 748 | Loss 0.1090 | Time 257.5237\n",
      "21:42:28 : Epoch 0001 | Step 0748 / 748 | Loss 0.1090 | Time 274.8012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:28,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:43:58 : Current AUC: 0.758561, Best AUC: 0.759838\n",
      "\n",
      "16334226 24501339\n",
      "train\n",
      "Current lr : 0.00034359738368000027\n",
      "21:44:29 : Epoch: 1:2\n",
      "21:44:48 : Epoch 0001 | Step 0050 / 748 | Loss 0.1095 | Time 19.9105\n",
      "21:45:07 : Epoch 0001 | Step 0100 / 748 | Loss 0.1096 | Time 38.2648\n",
      "21:45:25 : Epoch 0001 | Step 0150 / 748 | Loss 0.1094 | Time 56.6639\n",
      "21:45:44 : Epoch 0001 | Step 0200 / 748 | Loss 0.1095 | Time 75.7986\n",
      "21:46:02 : Epoch 0001 | Step 0250 / 748 | Loss 0.1094 | Time 93.8295\n",
      "21:46:22 : Epoch 0001 | Step 0300 / 748 | Loss 0.1093 | Time 112.9333\n",
      "21:46:41 : Epoch 0001 | Step 0350 / 748 | Loss 0.1093 | Time 132.2692\n",
      "21:46:59 : Epoch 0001 | Step 0400 / 748 | Loss 0.1092 | Time 150.8468\n",
      "21:47:18 : Epoch 0001 | Step 0450 / 748 | Loss 0.1093 | Time 169.2469\n",
      "21:47:36 : Epoch 0001 | Step 0500 / 748 | Loss 0.1093 | Time 187.4821\n",
      "21:47:54 : Epoch 0001 | Step 0550 / 748 | Loss 0.1093 | Time 205.8119\n",
      "21:48:12 : Epoch 0001 | Step 0600 / 748 | Loss 0.1092 | Time 223.8689\n",
      "21:48:31 : Epoch 0001 | Step 0650 / 748 | Loss 0.1092 | Time 242.7128\n",
      "21:48:50 : Epoch 0001 | Step 0700 / 748 | Loss 0.1092 | Time 261.4781\n",
      "21:49:07 : Epoch 0001 | Step 0748 / 748 | Loss 0.1092 | Time 278.8355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:29,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:50:38 : Current AUC: 0.757735, Best AUC: 0.759838\n",
      "\n",
      "24501339 32668452\n",
      "train\n",
      "Current lr : 0.00027487790694400024\n",
      "21:51:09 : Epoch: 1:3\n",
      "21:51:28 : Epoch 0001 | Step 0050 / 748 | Loss 0.1095 | Time 19.1808\n",
      "21:51:46 : Epoch 0001 | Step 0100 / 748 | Loss 0.1095 | Time 37.2097\n",
      "21:52:05 : Epoch 0001 | Step 0150 / 748 | Loss 0.1093 | Time 55.5556\n",
      "21:52:23 : Epoch 0001 | Step 0200 / 748 | Loss 0.1092 | Time 74.1056\n",
      "21:52:41 : Epoch 0001 | Step 0250 / 748 | Loss 0.1093 | Time 92.3907\n",
      "21:53:00 : Epoch 0001 | Step 0300 / 748 | Loss 0.1093 | Time 111.0513\n",
      "21:53:19 : Epoch 0001 | Step 0350 / 748 | Loss 0.1093 | Time 129.7553\n",
      "21:53:37 : Epoch 0001 | Step 0400 / 748 | Loss 0.1093 | Time 147.8815\n",
      "21:53:56 : Epoch 0001 | Step 0450 / 748 | Loss 0.1093 | Time 166.5427\n",
      "21:54:14 : Epoch 0001 | Step 0500 / 748 | Loss 0.1093 | Time 185.0630\n",
      "21:54:32 : Epoch 0001 | Step 0550 / 748 | Loss 0.1093 | Time 203.4917\n",
      "21:54:51 : Epoch 0001 | Step 0600 / 748 | Loss 0.1093 | Time 221.9965\n",
      "21:55:09 : Epoch 0001 | Step 0650 / 748 | Loss 0.1093 | Time 240.2281\n",
      "21:55:28 : Epoch 0001 | Step 0700 / 748 | Loss 0.1093 | Time 258.7746\n",
      "21:55:46 : Epoch 0001 | Step 0748 / 748 | Loss 0.1092 | Time 276.7973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:29,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:57:17 : Current AUC: 0.759559, Best AUC: 0.759838\n",
      "\n",
      "32668452 40835565\n",
      "train\n",
      "Current lr : 0.0002199023255552002\n",
      "21:57:47 : Epoch: 1:4\n",
      "21:58:06 : Epoch 0001 | Step 0050 / 748 | Loss 0.1091 | Time 18.7438\n",
      "21:58:23 : Epoch 0001 | Step 0100 / 748 | Loss 0.1093 | Time 36.3288\n",
      "21:58:41 : Epoch 0001 | Step 0150 / 748 | Loss 0.1092 | Time 54.5417\n",
      "21:59:00 : Epoch 0001 | Step 0200 / 748 | Loss 0.1090 | Time 72.7358\n",
      "21:59:18 : Epoch 0001 | Step 0250 / 748 | Loss 0.1092 | Time 90.9307\n",
      "21:59:36 : Epoch 0001 | Step 0300 / 748 | Loss 0.1093 | Time 108.9955\n",
      "21:59:54 : Epoch 0001 | Step 0350 / 748 | Loss 0.1093 | Time 127.1144\n",
      "22:00:12 : Epoch 0001 | Step 0400 / 748 | Loss 0.1092 | Time 145.5691\n",
      "22:00:32 : Epoch 0001 | Step 0450 / 748 | Loss 0.1092 | Time 164.9777\n",
      "22:00:50 : Epoch 0001 | Step 0500 / 748 | Loss 0.1091 | Time 183.5498\n",
      "22:01:09 : Epoch 0001 | Step 0550 / 748 | Loss 0.1091 | Time 201.8453\n",
      "22:01:27 : Epoch 0001 | Step 0600 / 748 | Loss 0.1091 | Time 220.0628\n",
      "22:01:46 : Epoch 0001 | Step 0650 / 748 | Loss 0.1091 | Time 238.8328\n",
      "22:02:04 : Epoch 0001 | Step 0700 / 748 | Loss 0.1091 | Time 257.4836\n",
      "22:02:22 : Epoch 0001 | Step 0748 / 748 | Loss 0.1091 | Time 274.9747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:27,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:03:50 : Current AUC: 0.758918, Best AUC: 0.759838\n",
      "\n",
      "40835565 49002678\n",
      "train\n",
      "Current lr : 0.00017592186044416018\n",
      "22:04:21 : Epoch: 1:5\n",
      "22:04:39 : Epoch 0001 | Step 0050 / 748 | Loss 0.1093 | Time 18.4324\n",
      "22:04:57 : Epoch 0001 | Step 0100 / 748 | Loss 0.1094 | Time 36.4707\n",
      "22:05:15 : Epoch 0001 | Step 0150 / 748 | Loss 0.1091 | Time 54.4702\n",
      "22:05:33 : Epoch 0001 | Step 0200 / 748 | Loss 0.1091 | Time 72.3537\n",
      "22:05:51 : Epoch 0001 | Step 0250 / 748 | Loss 0.1093 | Time 90.4584\n",
      "22:06:10 : Epoch 0001 | Step 0300 / 748 | Loss 0.1093 | Time 108.7639\n",
      "22:06:28 : Epoch 0001 | Step 0350 / 748 | Loss 0.1092 | Time 126.8273\n",
      "22:06:46 : Epoch 0001 | Step 0400 / 748 | Loss 0.1093 | Time 144.9935\n",
      "22:07:04 : Epoch 0001 | Step 0450 / 748 | Loss 0.1092 | Time 163.1100\n",
      "22:07:22 : Epoch 0001 | Step 0500 / 748 | Loss 0.1092 | Time 181.3096\n",
      "22:07:40 : Epoch 0001 | Step 0550 / 748 | Loss 0.1092 | Time 199.2827\n",
      "22:07:59 : Epoch 0001 | Step 0600 / 748 | Loss 0.1092 | Time 217.5492\n",
      "22:08:17 : Epoch 0001 | Step 0650 / 748 | Loss 0.1092 | Time 235.6380\n",
      "22:08:35 : Epoch 0001 | Step 0700 / 748 | Loss 0.1092 | Time 253.7651\n",
      "22:08:52 : Epoch 0001 | Step 0748 / 748 | Loss 0.1092 | Time 270.9634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:27,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:10:21 : Current AUC: 0.757964, Best AUC: 0.759838\n",
      "\n",
      "49002678 57169791\n",
      "train\n",
      "Current lr : 0.00014073748835532815\n",
      "22:10:51 : Epoch: 1:6\n",
      "22:11:10 : Epoch 0001 | Step 0050 / 748 | Loss 0.1097 | Time 18.5151\n",
      "22:11:28 : Epoch 0001 | Step 0100 / 748 | Loss 0.1094 | Time 37.0240\n",
      "22:11:46 : Epoch 0001 | Step 0150 / 748 | Loss 0.1091 | Time 54.6774\n",
      "22:12:04 : Epoch 0001 | Step 0200 / 748 | Loss 0.1090 | Time 72.8963\n",
      "22:12:22 : Epoch 0001 | Step 0250 / 748 | Loss 0.1091 | Time 91.0985\n",
      "22:12:40 : Epoch 0001 | Step 0300 / 748 | Loss 0.1092 | Time 108.9668\n",
      "22:12:58 : Epoch 0001 | Step 0350 / 748 | Loss 0.1093 | Time 127.0207\n",
      "22:13:16 : Epoch 0001 | Step 0400 / 748 | Loss 0.1093 | Time 144.8492\n",
      "22:13:34 : Epoch 0001 | Step 0450 / 748 | Loss 0.1093 | Time 162.5677\n",
      "22:13:52 : Epoch 0001 | Step 0500 / 748 | Loss 0.1093 | Time 180.4445\n",
      "22:14:10 : Epoch 0001 | Step 0550 / 748 | Loss 0.1092 | Time 198.4593\n",
      "22:14:28 : Epoch 0001 | Step 0600 / 748 | Loss 0.1092 | Time 216.7042\n",
      "22:14:46 : Epoch 0001 | Step 0650 / 748 | Loss 0.1092 | Time 234.8077\n",
      "22:15:04 : Epoch 0001 | Step 0700 / 748 | Loss 0.1092 | Time 252.6175\n",
      "22:15:22 : Epoch 0001 | Step 0748 / 748 | Loss 0.1093 | Time 270.4462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:28,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:16:52 : Current AUC: 0.759547, Best AUC: 0.759838\n",
      "\n",
      "57169791 65336904\n",
      "train\n",
      "Current lr : 0.00011258999068426252\n",
      "22:17:22 : Epoch: 1:7\n",
      "22:17:41 : Epoch 0001 | Step 0050 / 748 | Loss 0.1088 | Time 18.9923\n",
      "22:17:59 : Epoch 0001 | Step 0100 / 748 | Loss 0.1091 | Time 36.6818\n",
      "22:18:17 : Epoch 0001 | Step 0150 / 748 | Loss 0.1090 | Time 54.4619\n",
      "22:18:35 : Epoch 0001 | Step 0200 / 748 | Loss 0.1090 | Time 72.2078\n",
      "22:18:52 : Epoch 0001 | Step 0250 / 748 | Loss 0.1092 | Time 90.0831\n",
      "22:19:10 : Epoch 0001 | Step 0300 / 748 | Loss 0.1092 | Time 108.0473\n",
      "22:19:28 : Epoch 0001 | Step 0350 / 748 | Loss 0.1091 | Time 125.5560\n",
      "22:19:46 : Epoch 0001 | Step 0400 / 748 | Loss 0.1092 | Time 143.7863\n",
      "22:20:04 : Epoch 0001 | Step 0450 / 748 | Loss 0.1093 | Time 161.7372\n",
      "22:20:22 : Epoch 0001 | Step 0500 / 748 | Loss 0.1092 | Time 179.6270\n",
      "22:20:40 : Epoch 0001 | Step 0550 / 748 | Loss 0.1092 | Time 197.8153\n",
      "22:20:58 : Epoch 0001 | Step 0600 / 748 | Loss 0.1092 | Time 215.4751\n",
      "22:21:16 : Epoch 0001 | Step 0650 / 748 | Loss 0.1092 | Time 233.6613\n",
      "22:21:34 : Epoch 0001 | Step 0700 / 748 | Loss 0.1092 | Time 251.7341\n",
      "22:21:51 : Epoch 0001 | Step 0748 / 748 | Loss 0.1092 | Time 269.0948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:28,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:23:21 : Current AUC: 0.759481, Best AUC: 0.759838\n",
      "\n",
      "65336904 73504017\n",
      "train\n",
      "Current lr : 9.007199254741002e-05\n",
      "22:23:52 : Epoch: 1:8\n",
      "22:24:11 : Epoch 0001 | Step 0050 / 748 | Loss 0.1095 | Time 19.6167\n",
      "22:24:29 : Epoch 0001 | Step 0100 / 748 | Loss 0.1094 | Time 37.6183\n",
      "22:24:47 : Epoch 0001 | Step 0150 / 748 | Loss 0.1093 | Time 55.5946\n",
      "22:25:05 : Epoch 0001 | Step 0200 / 748 | Loss 0.1094 | Time 73.5942\n",
      "22:25:23 : Epoch 0001 | Step 0250 / 748 | Loss 0.1094 | Time 91.5144\n",
      "22:25:41 : Epoch 0001 | Step 0300 / 748 | Loss 0.1093 | Time 109.6589\n",
      "22:26:00 : Epoch 0001 | Step 0350 / 748 | Loss 0.1093 | Time 127.8212\n",
      "22:26:17 : Epoch 0001 | Step 0400 / 748 | Loss 0.1093 | Time 145.4620\n",
      "22:26:35 : Epoch 0001 | Step 0450 / 748 | Loss 0.1093 | Time 163.6351\n",
      "22:26:54 : Epoch 0001 | Step 0500 / 748 | Loss 0.1093 | Time 182.0205\n",
      "22:27:12 : Epoch 0001 | Step 0550 / 748 | Loss 0.1092 | Time 199.8732\n",
      "22:27:30 : Epoch 0001 | Step 0600 / 748 | Loss 0.1093 | Time 217.9224\n",
      "22:27:48 : Epoch 0001 | Step 0650 / 748 | Loss 0.1093 | Time 236.1386\n",
      "22:28:06 : Epoch 0001 | Step 0700 / 748 | Loss 0.1093 | Time 254.1719\n",
      "22:28:24 : Epoch 0001 | Step 0748 / 748 | Loss 0.1093 | Time 272.4800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:26,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:29:52 : Current AUC: 0.758468, Best AUC: 0.759838\n",
      "\n",
      "73504017 81671130\n",
      "train\n",
      "Current lr : 7.205759403792802e-05\n",
      "22:30:22 : Epoch: 1:9\n",
      "22:30:41 : Epoch 0001 | Step 0050 / 748 | Loss 0.1091 | Time 18.6739\n",
      "22:30:59 : Epoch 0001 | Step 0100 / 748 | Loss 0.1090 | Time 36.3790\n",
      "22:31:16 : Epoch 0001 | Step 0150 / 748 | Loss 0.1091 | Time 53.9896\n",
      "22:31:34 : Epoch 0001 | Step 0200 / 748 | Loss 0.1091 | Time 72.1138\n",
      "22:31:53 : Epoch 0001 | Step 0250 / 748 | Loss 0.1091 | Time 90.3627\n",
      "22:32:11 : Epoch 0001 | Step 0300 / 748 | Loss 0.1091 | Time 108.5525\n",
      "22:32:29 : Epoch 0001 | Step 0350 / 748 | Loss 0.1090 | Time 126.9107\n",
      "22:32:48 : Epoch 0001 | Step 0400 / 748 | Loss 0.1090 | Time 145.5927\n",
      "22:33:06 : Epoch 0001 | Step 0450 / 748 | Loss 0.1090 | Time 163.6695\n",
      "22:33:24 : Epoch 0001 | Step 0500 / 748 | Loss 0.1090 | Time 182.1961\n",
      "22:33:43 : Epoch 0001 | Step 0550 / 748 | Loss 0.1091 | Time 200.3539\n",
      "22:34:01 : Epoch 0001 | Step 0600 / 748 | Loss 0.1091 | Time 218.5595\n",
      "22:34:19 : Epoch 0001 | Step 0650 / 748 | Loss 0.1091 | Time 236.7601\n",
      "22:34:37 : Epoch 0001 | Step 0700 / 748 | Loss 0.1091 | Time 254.8271\n",
      "22:34:55 : Epoch 0001 | Step 0748 / 748 | Loss 0.1091 | Time 272.4388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:30,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:36:27 : Current AUC: 0.758208, Best AUC: 0.759838\n",
      "\n",
      "0 8167113\n",
      "train\n",
      "Current lr : 5.764607523034242e-05\n",
      "22:36:58 : Epoch: 2:0\n",
      "22:37:16 : Epoch 0001 | Step 0050 / 748 | Loss 0.1089 | Time 18.0874\n",
      "22:37:35 : Epoch 0001 | Step 0100 / 748 | Loss 0.1089 | Time 36.3787\n",
      "22:37:53 : Epoch 0001 | Step 0150 / 748 | Loss 0.1088 | Time 54.6882\n",
      "22:38:12 : Epoch 0001 | Step 0200 / 748 | Loss 0.1089 | Time 73.9347\n",
      "22:38:31 : Epoch 0001 | Step 0250 / 748 | Loss 0.1091 | Time 92.3054\n",
      "22:38:48 : Epoch 0001 | Step 0300 / 748 | Loss 0.1090 | Time 110.1186\n",
      "22:39:06 : Epoch 0001 | Step 0350 / 748 | Loss 0.1090 | Time 128.0149\n",
      "22:39:25 : Epoch 0001 | Step 0400 / 748 | Loss 0.1090 | Time 146.2147\n",
      "22:39:43 : Epoch 0001 | Step 0450 / 748 | Loss 0.1090 | Time 164.4307\n",
      "22:40:01 : Epoch 0001 | Step 0500 / 748 | Loss 0.1090 | Time 182.5301\n",
      "22:40:20 : Epoch 0001 | Step 0550 / 748 | Loss 0.1090 | Time 202.1747\n",
      "22:40:39 : Epoch 0001 | Step 0600 / 748 | Loss 0.1089 | Time 220.8300\n",
      "22:40:58 : Epoch 0001 | Step 0650 / 748 | Loss 0.1090 | Time 239.2410\n",
      "22:41:15 : Epoch 0001 | Step 0700 / 748 | Loss 0.1090 | Time 257.2022\n",
      "22:41:33 : Epoch 0001 | Step 0748 / 748 | Loss 0.1090 | Time 274.5942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:27,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:43:02 : Current AUC: 0.758700, Best AUC: 0.759838\n",
      "\n",
      "8167113 16334226\n",
      "train\n",
      "Current lr : 4.611686018427394e-05\n",
      "22:43:32 : Epoch: 2:1\n",
      "22:43:51 : Epoch 0001 | Step 0050 / 748 | Loss 0.1091 | Time 18.9064\n",
      "22:44:11 : Epoch 0001 | Step 0100 / 748 | Loss 0.1090 | Time 38.4717\n",
      "22:44:29 : Epoch 0001 | Step 0150 / 748 | Loss 0.1090 | Time 56.9478\n",
      "22:44:48 : Epoch 0001 | Step 0200 / 748 | Loss 0.1090 | Time 75.7994\n",
      "22:45:07 : Epoch 0001 | Step 0250 / 748 | Loss 0.1090 | Time 94.7687\n",
      "22:45:27 : Epoch 0001 | Step 0300 / 748 | Loss 0.1090 | Time 114.2685\n",
      "22:45:46 : Epoch 0001 | Step 0350 / 748 | Loss 0.1089 | Time 133.6376\n",
      "22:46:06 : Epoch 0001 | Step 0400 / 748 | Loss 0.1089 | Time 153.3668\n",
      "22:46:26 : Epoch 0001 | Step 0450 / 748 | Loss 0.1089 | Time 173.7853\n",
      "22:46:45 : Epoch 0001 | Step 0500 / 748 | Loss 0.1090 | Time 192.8605\n",
      "22:47:04 : Epoch 0001 | Step 0550 / 748 | Loss 0.1090 | Time 211.7500\n",
      "22:47:22 : Epoch 0001 | Step 0600 / 748 | Loss 0.1090 | Time 229.9889\n",
      "22:47:41 : Epoch 0001 | Step 0650 / 748 | Loss 0.1090 | Time 248.6853\n",
      "22:48:00 : Epoch 0001 | Step 0700 / 748 | Loss 0.1090 | Time 268.0233\n",
      "22:48:18 : Epoch 0001 | Step 0748 / 748 | Loss 0.1090 | Time 285.6793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [01:25,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22:49:45 : Current AUC: 0.758561, Best AUC: 0.759838\n",
      "\n",
      "16334226 24501339\n",
      "train\n",
      "Current lr : 3.6893488147419155e-05\n",
      "22:50:15 : Epoch: 2:2\n",
      "22:50:35 : Epoch 0001 | Step 0050 / 748 | Loss 0.1089 | Time 19.0779\n",
      "22:50:53 : Epoch 0001 | Step 0100 / 748 | Loss 0.1092 | Time 37.7544\n",
      "22:51:12 : Epoch 0001 | Step 0150 / 748 | Loss 0.1092 | Time 56.3203\n",
      "22:51:30 : Epoch 0001 | Step 0200 / 748 | Loss 0.1092 | Time 74.5187\n",
      "22:51:49 : Epoch 0001 | Step 0250 / 748 | Loss 0.1092 | Time 93.2527\n",
      "22:52:08 : Epoch 0001 | Step 0300 / 748 | Loss 0.1092 | Time 112.6930\n",
      "22:52:27 : Epoch 0001 | Step 0350 / 748 | Loss 0.1092 | Time 131.1224\n",
      "22:52:46 : Epoch 0001 | Step 0400 / 748 | Loss 0.1093 | Time 150.1082\n",
      "22:53:05 : Epoch 0001 | Step 0450 / 748 | Loss 0.1092 | Time 169.2216\n",
      "22:53:24 : Epoch 0001 | Step 0500 / 748 | Loss 0.1092 | Time 188.1911\n",
      "22:53:43 : Epoch 0001 | Step 0550 / 748 | Loss 0.1092 | Time 207.6657\n",
      "22:54:02 : Epoch 0001 | Step 0600 / 748 | Loss 0.1092 | Time 226.5144\n",
      "22:54:20 : Epoch 0001 | Step 0650 / 748 | Loss 0.1092 | Time 244.8149\n",
      "22:54:38 : Epoch 0001 | Step 0700 / 748 | Loss 0.1092 | Time 262.7974\n",
      "22:54:56 : Epoch 0001 | Step 0748 / 748 | Loss 0.1092 | Time 280.3137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "219it [01:15,  2.90it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6754/2950000948.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mepoch_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mbest_auc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_and_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fcn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_auc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_6754/3465505282.py\u001b[0m in \u001b[0;36mtrain_and_eval\u001b[0;34m(model, train_loader, valid_loader, epochs, optimizer, loss_fcn, scheduler, device, best_auc, j, ii)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mvalid_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0mdoc_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnume_fea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mdoc_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'docid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/sw0/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/sw0/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/sw0/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/sw0/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/sw0/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "len_=81671133\n",
    "best_auc=0\n",
    "for j in range(5):\n",
    "    ii=-1\n",
    "    for i in range(0,len_,round(len_/10)):\n",
    "        ii+=1\n",
    "        right=i+round(len_/10)\n",
    "        if right>=len_:\n",
    "            break\n",
    "        print(i,right)\n",
    "        df_train_user_doc=pd.read_pickle('../../data/wj/df_train_user_doc_0_1_'+str(i)+'_'+str(right)+'_64.pkl')\n",
    "#         df_train_user_doc=pd.merge(df_train_user_doc,title_,how='left',on='docid')\n",
    "        \n",
    "        train, valid = train_test_split(df_train_user_doc, test_size=0.25, random_state=2021)\n",
    "#         train_loader，valid_loader\n",
    "        train_dataset = Data.TensorDataset(torch.LongTensor(np.stack(train['docid'].values,axis=0)),\n",
    "                                           torch.FloatTensor(train[dense_features].values),\n",
    "                                           torch.FloatTensor(train['click'].values), )\n",
    "        train_loader = Data.DataLoader(dataset=train_dataset, batch_size=8192, shuffle=True)\n",
    "        \n",
    "        valid_dataset = Data.TensorDataset(torch.LongTensor(np.stack(valid['docid'].values,axis=0)),\n",
    "                                           torch.FloatTensor(valid[dense_features].values),\n",
    "                                           torch.FloatTensor(valid['click'].values))\n",
    "        valid_loader = Data.DataLoader(dataset=valid_dataset, batch_size=8192, shuffle=False)\n",
    "#         train\n",
    "        print('train')\n",
    "        epoch_=1\n",
    "        best_auc=train_and_eval(model, train_loader, valid_loader, epoch_, optimizer, loss_fcn, scheduler, device,best_auc,j,ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test_user_doc=pd.read_pickle('../../data/wj/df_test_user_doc_64_new.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "def predict(test_df, s_feat, den_feat, model, device,modeln):\n",
    "    test_dataset = Data.TensorDataset(torch.LongTensor(np.stack(test_df['docid'].values,axis=0)),\n",
    "                                           torch.FloatTensor(test_df[dense_features].values))\n",
    "    test_loader = Data.DataLoader(dataset=test_dataset, batch_size=4096, shuffle=False)\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        test_preds = []\n",
    "        for idx, x in tqdm(enumerate(test_loader)):\n",
    "            doc_id, nume_fea = x[0], x[1]\n",
    "            doc_id=pd.DataFrame(doc_id,columns=['docid'])\n",
    "            doc_title=pd.merge(doc_id,title_,how='left',on='docid')\n",
    "            title_0=torch.FloatTensor(np.stack(doc_title['title_'],axis=0))\n",
    "\n",
    "            nume_fea, title_0 = nume_fea.to(device), title_0.to(device)\n",
    "            pred = model(nume_fea, title_0).reshape(-1).data.cpu().numpy().tolist()\n",
    "            \n",
    "            test_preds.extend(pred)\n",
    "        id_list = list(range(0, len(test_preds)))\n",
    "        out_dict = {\"id\": id_list, \"pred\": test_preds}\n",
    "        out_df = pd.DataFrame(out_dict)\n",
    "        out_df.to_csv('../../data/wj/bert_best/'+pp+'/bert_result_user_'+modeln+'.csv', sep=',', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:02,  6.17it/s]\n"
     ]
    }
   ],
   "source": [
    "modeln='0.7598_0_8_12_21_13_24_11'\n",
    "model = fn_cls(device,nume_fea_size=len(dense_features))\n",
    "model.load_state_dict(torch.load('../../data/wj/bert_best/'+pp+'/bert_best_'+modeln+'.pth'))\n",
    "\n",
    "model = model.to(device)\n",
    "model.eval()  # 把模型转为test模式\n",
    "predict(df_test_user_doc, sparse_features, dense_features, model, device,modeln)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sw0",
   "language": "python",
   "name": "sw0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
