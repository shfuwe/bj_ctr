{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.core.frame import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFM(nn.Module):\n",
    "    def __init__(self, cate_fea_nuniqs, nume_fea_size=0, emb_size=8,\n",
    "                 hid_dims=[256, 128], num_classes=1, dropout=[0.2, 0.2]):\n",
    "        \"\"\"\n",
    "        cate_fea_nuniqs: 类别特征的唯一值个数列表，也就是每个类别特征的vocab_size所组成的列表\n",
    "        nume_fea_size: 数值特征的个数，该模型会考虑到输入全为类别型，即没有数值特征的情况\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.cate_fea_size = len(cate_fea_nuniqs)\n",
    "        self.nume_fea_size = nume_fea_size\n",
    "\n",
    "        \"\"\"FM部分\"\"\"\n",
    "        # 一阶\n",
    "        if self.nume_fea_size != 0:\n",
    "            self.fm_1st_order_dense = nn.Linear(self.nume_fea_size, 1)  # 数值特征的一阶表示\n",
    "        self.fm_1st_order_sparse_emb = nn.ModuleList([\n",
    "            nn.Embedding(voc_size, 1) for voc_size in cate_fea_nuniqs])  # 类别特征的一阶表示\n",
    "        self.fm_1st_order_title = nn.Linear(128, 1)\n",
    "        \n",
    "        # 二阶\n",
    "        self.fm_2nd_order_sparse_emb = nn.ModuleList([\n",
    "            nn.Embedding(voc_size, emb_size) for voc_size in cate_fea_nuniqs])  # 类别特征的二阶表示\n",
    "\n",
    "        \"\"\"DNN部分\"\"\"\n",
    "        self.all_dims = [self.cate_fea_size * emb_size] + hid_dims\n",
    "        self.dense_linear = nn.Linear(self.nume_fea_size, self.cate_fea_size * emb_size)  # 数值特征的维度变换到FM输出维度一致\n",
    "        self.title_linear = nn.Linear(128, self.cate_fea_size * emb_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        # for DNN\n",
    "        for i in range(1, len(self.all_dims)):\n",
    "            setattr(self, 'linear_' + str(i), nn.Linear(self.all_dims[i - 1], self.all_dims[i]))\n",
    "            setattr(self, 'batchNorm_' + str(i), nn.BatchNorm1d(self.all_dims[i]))\n",
    "            setattr(self, 'activation_' + str(i), nn.ReLU())\n",
    "            setattr(self, 'dropout_' + str(i), nn.Dropout(dropout[i - 1]))\n",
    "        # for output\n",
    "        self.dnn_linear = nn.Linear(hid_dims[-1], num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, X_sparse, X_dense, X_title):\n",
    "        \"\"\"\n",
    "        X_sparse: 类别型特征输入  [bs, cate_fea_size]\n",
    "        X_dense: 数值型特征输入（可能没有）  [bs, dense_fea_size]\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"FM 一阶部分\"\"\"\n",
    "        fm_1st_sparse_res = [emb(X_sparse[:, i].unsqueeze(1)).view(-1, 1)\n",
    "                             for i, emb in enumerate(self.fm_1st_order_sparse_emb)]\n",
    "        fm_1st_sparse_res = torch.cat(fm_1st_sparse_res, dim=1)  # [bs, cate_fea_size]\n",
    "        fm_1st_sparse_res = torch.sum(fm_1st_sparse_res, 1, keepdim=True)  # [bs, 1]\n",
    "        \n",
    "        fm_1st_title_res=self.fm_1st_order_title(X_title)\n",
    "        \n",
    "        if X_dense is not None:\n",
    "            fm_1st_dense_res = self.fm_1st_order_dense(X_dense)\n",
    "            fm_1st_part = fm_1st_sparse_res + fm_1st_dense_res+fm_1st_title_res\n",
    "        else:\n",
    "            fm_1st_part = fm_1st_sparse_res+fm_1st_title_res  # [bs, 1]\n",
    "        \"\"\"FM 一阶部分\"\"\"\n",
    "        \n",
    "        \"\"\"FM 二阶部分\"\"\"\n",
    "        fm_2nd_order_res = [emb(X_sparse[:, i].unsqueeze(1)) for i, emb in enumerate(self.fm_2nd_order_sparse_emb)]\n",
    "        fm_2nd_concat_1d = torch.cat(fm_2nd_order_res, dim=1)  # [bs, n, emb_size]  n为类别型特征个数(cate_fea_size)\n",
    "\n",
    "        # 先求和再平方\n",
    "        sum_embed = torch.sum(fm_2nd_concat_1d, 1)  # [bs, emb_size]\n",
    "        square_sum_embed = sum_embed * sum_embed  # [bs, emb_size]\n",
    "        # 先平方再求和\n",
    "        square_embed = fm_2nd_concat_1d * fm_2nd_concat_1d  # [bs, n, emb_size]\n",
    "        sum_square_embed = torch.sum(square_embed, 1)  # [bs, emb_size]\n",
    "        # 相减除以2\n",
    "        sub = square_sum_embed - sum_square_embed\n",
    "        sub = sub * 0.5  # [bs, emb_size]\n",
    "\n",
    "        fm_2nd_part = torch.sum(sub, 1, keepdim=True)  # [bs, 1]\n",
    "        \"\"\"FM 二阶部分\"\"\"\n",
    "        \n",
    "        \"\"\"DNN部分\"\"\"\n",
    "        dnn_out = torch.flatten(fm_2nd_concat_1d, 1)  # [bs, n * emb_size]\n",
    "        if X_title is not None:\n",
    "            title_out=self.relu(self.title_linear(X_title))\n",
    "            dnn_out= dnn_out+title_out\n",
    "        \n",
    "        if X_dense is not None:\n",
    "            dense_out = self.relu(self.dense_linear(X_dense))  # [bs, n * emb_size]\n",
    "            dnn_out = dnn_out + dense_out  # [bs, n * emb_size]\n",
    "\n",
    "        for i in range(1, len(self.all_dims)):\n",
    "            dnn_out = getattr(self, 'linear_' + str(i))(dnn_out)\n",
    "            dnn_out = getattr(self, 'batchNorm_' + str(i))(dnn_out)\n",
    "            dnn_out = getattr(self, 'activation_' + str(i))(dnn_out)\n",
    "            dnn_out = getattr(self, 'dropout_' + str(i))(dnn_out)\n",
    "\n",
    "        dnn_out = self.dnn_linear(dnn_out)  # [bs, 1]\n",
    "        \"\"\"DNN部分\"\"\"\n",
    "        \n",
    "        out = fm_1st_part + fm_2nd_part + dnn_out  # [bs, 1]\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "doc_feat = pd.read_pickle('../../data/wj/doc.pkl')\n",
    "user_feat = pd.read_pickle('../../data/wj/user.pkl')\n",
    "\n",
    "\n",
    "sparse_features = ['userid', 'docid', 'network', 'hour', 'device', 'os', 'province',\n",
    "                   'city', 'age', 'gender', 'category1st', 'category2nd',\n",
    "                   'pub_date', 'keyword0', 'keyword1', 'keyword2', 'keyword3', 'keyword4']\n",
    "\n",
    "dense_features = ['refresh', 'picnum',\n",
    "                  'userid_click_mean','userid_click_count' ,'userid_duration_mean' ,'userid_picnum_mean',\n",
    "                    'docid_click_mean','docid_click_count','docid_duration_mean','docid_picnum_mean',\n",
    "                    'category1st_click_mean','category1st_click_count','category1st_duration_mean','category1st_picnum_mean',\n",
    "                    'category2nd_click_mean','category2nd_click_count','category2nd_duration_mean','category2nd_picnum_mean',\n",
    "                    'keyword0_click_mean','keyword0_click_count','keyword0_duration_mean','keyword0_picnum_mean',\n",
    "                 'network_click_mean', 'network_click_count', 'network_duration_mean', \n",
    "                  'refresh_click_mean', 'refresh_click_count', 'refresh_duration_mean',\n",
    "                  'device_click_mean', 'device_click_count', 'device_duration_mean', \n",
    "                  'os_click_mean', 'os_click_count', 'os_duration_mean', \n",
    "                  'province_click_mean', 'province_click_count', 'province_duration_mean', \n",
    "                  'city_click_mean', 'city_click_count', 'city_duration_mean', \n",
    "                  'age_click_mean', 'age_click_count', 'age_duration_mean', \n",
    "                  'gender_click_mean', 'gender_click_count', 'gender_duration_mean'\n",
    "                 ]\n",
    "\n",
    "cate_fea_nuniqs = []\n",
    "cate_fea_nuniqs.append(user_feat['userid'].nunique() + 1)\n",
    "cate_fea_nuniqs.append(doc_feat['docid'].nunique() + 1)\n",
    "cate_fea_nuniqs.append(6)  # network\n",
    "cate_fea_nuniqs.append(13)  # hour\n",
    "cate_fea_nuniqs.append(user_feat['device'].nunique())\n",
    "cate_fea_nuniqs.append(user_feat['os'].nunique())\n",
    "cate_fea_nuniqs.append(user_feat['province'].nunique())\n",
    "cate_fea_nuniqs.append(user_feat['city'].nunique())\n",
    "cate_fea_nuniqs.append(user_feat['age'].nunique())\n",
    "cate_fea_nuniqs.append(user_feat['gender'].nunique())\n",
    "cate_fea_nuniqs.append(doc_feat['category1st'].nunique())\n",
    "cate_fea_nuniqs.append(doc_feat['category2nd'].nunique())\n",
    "cate_fea_nuniqs.append(doc_feat['pub_date'].nunique())\n",
    "keyword_nunique = max(doc_feat['keyword0'].max(), doc_feat['keyword1'].max(), doc_feat['keyword2'].max()\n",
    "                      , doc_feat['keyword3'].max(), doc_feat['keyword4'].max()) + 1\n",
    "cate_fea_nuniqs.append(keyword_nunique)\n",
    "cate_fea_nuniqs.append(keyword_nunique)\n",
    "cate_fea_nuniqs.append(keyword_nunique)\n",
    "cate_fea_nuniqs.append(keyword_nunique)\n",
    "cate_fea_nuniqs.append(keyword_nunique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>docid</th>\n",
       "      <th>network</th>\n",
       "      <th>refresh</th>\n",
       "      <th>hour</th>\n",
       "      <th>device</th>\n",
       "      <th>os</th>\n",
       "      <th>province</th>\n",
       "      <th>city</th>\n",
       "      <th>age</th>\n",
       "      <th>...</th>\n",
       "      <th>city_click_mean</th>\n",
       "      <th>city_click_count</th>\n",
       "      <th>city_duration_mean</th>\n",
       "      <th>age_click_mean</th>\n",
       "      <th>age_click_count</th>\n",
       "      <th>age_duration_mean</th>\n",
       "      <th>gender_click_mean</th>\n",
       "      <th>gender_click_count</th>\n",
       "      <th>gender_duration_mean</th>\n",
       "      <th>title_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>480541</td>\n",
       "      <td>296276</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1479</td>\n",
       "      <td>0</td>\n",
       "      <td>224</td>\n",
       "      <td>506</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130476</td>\n",
       "      <td>0.140501</td>\n",
       "      <td>0.066269</td>\n",
       "      <td>0.973272</td>\n",
       "      <td>0.512925</td>\n",
       "      <td>0.768686</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.86893</td>\n",
       "      <td>[-0.6367044, -0.37391523, 0.75519204, 0.235412...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>319162</td>\n",
       "      <td>304285</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2810</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>654</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132635</td>\n",
       "      <td>0.048351</td>\n",
       "      <td>0.064371</td>\n",
       "      <td>0.973272</td>\n",
       "      <td>0.512925</td>\n",
       "      <td>0.768686</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.86893</td>\n",
       "      <td>[-0.32206813, -0.17239709, -0.016561577, 0.351...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>343230</td>\n",
       "      <td>323224</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1224</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>560</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144378</td>\n",
       "      <td>0.035406</td>\n",
       "      <td>0.070138</td>\n",
       "      <td>0.793110</td>\n",
       "      <td>0.740016</td>\n",
       "      <td>0.852092</td>\n",
       "      <td>0.99988</td>\n",
       "      <td>0.32075</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>[-0.34045646, 0.014710239, 0.6830002, -0.37456...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>337541</td>\n",
       "      <td>319291</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>980</td>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.149390</td>\n",
       "      <td>0.098312</td>\n",
       "      <td>0.078247</td>\n",
       "      <td>0.793110</td>\n",
       "      <td>0.740016</td>\n",
       "      <td>0.852092</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.86893</td>\n",
       "      <td>[-0.60920477, 0.028061464, 1.4830661, 0.401224...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>672656</td>\n",
       "      <td>323911</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1785</td>\n",
       "      <td>0</td>\n",
       "      <td>195</td>\n",
       "      <td>622</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129463</td>\n",
       "      <td>0.047937</td>\n",
       "      <td>0.060501</td>\n",
       "      <td>0.984465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.86893</td>\n",
       "      <td>[-0.3812312, 0.084279664, 0.36184198, 0.380201...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid   docid  network  refresh  hour  device  os  province  city  age  \\\n",
       "0  480541  296276        2        4   4.0    1479   0       224   506    2   \n",
       "1  319162  304285        2        2  12.0    2810   0       216   654    2   \n",
       "2  343230  323224        2       10  10.0    1224   0       280   560    0   \n",
       "3  337541  319291        2       10   8.0     980   0       242   360    0   \n",
       "4  672656  323911        2       11   7.0    1785   0       195   622    3   \n",
       "\n",
       "   ...  city_click_mean  city_click_count  city_duration_mean  age_click_mean  \\\n",
       "0  ...         0.130476          0.140501            0.066269        0.973272   \n",
       "1  ...         0.132635          0.048351            0.064371        0.973272   \n",
       "2  ...         0.144378          0.035406            0.070138        0.793110   \n",
       "3  ...         0.149390          0.098312            0.078247        0.793110   \n",
       "4  ...         0.129463          0.047937            0.060501        0.984465   \n",
       "\n",
       "   age_click_count  age_duration_mean  gender_click_mean  gender_click_count  \\\n",
       "0         0.512925           0.768686            1.00000             1.00000   \n",
       "1         0.512925           0.768686            1.00000             1.00000   \n",
       "2         0.740016           0.852092            0.99988             0.32075   \n",
       "3         0.740016           0.852092            1.00000             1.00000   \n",
       "4         1.000000           1.000000            1.00000             1.00000   \n",
       "\n",
       "   gender_duration_mean                                             title_  \n",
       "0               0.86893  [-0.6367044, -0.37391523, 0.75519204, 0.235412...  \n",
       "1               0.86893  [-0.32206813, -0.17239709, -0.016561577, 0.351...  \n",
       "2               1.00000  [-0.34045646, 0.014710239, 0.6830002, -0.37456...  \n",
       "3               0.86893  [-0.60920477, 0.028061464, 1.4830661, 0.401224...  \n",
       "4               0.86893  [-0.3812312, 0.084279664, 0.36184198, 0.380201...  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "title_=pd.read_pickle('../../data/wj/title_embedding.pkl')\n",
    "del title_['title']\n",
    "df_test_user_doc=pd.read_pickle('../../data/wj/df_test_user_doc_64_new.pkl')\n",
    "df_test_user_doc=pd.merge(df_test_user_doc,title_,how='left',on='docid')\n",
    "df_test_user_doc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def predict(test_df, s_feat, den_feat, model, device,modeln):\n",
    "    test_dataset = Data.TensorDataset(torch.LongTensor(test_df[s_feat].values),\n",
    "                                       torch.FloatTensor(test_df[den_feat].values),\n",
    "                                     torch.FloatTensor(np.stack(test_df['title_'].values,axis=0)))\n",
    "    \n",
    "    test_loader = Data.DataLoader(dataset=test_dataset, batch_size=4096, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        test_preds = []\n",
    "        for idx, x in tqdm(enumerate(test_loader)):\n",
    "            cate_fea, nume_fea ,title_fea= x[0], x[1], x[2]\n",
    "            cate_fea, nume_fea ,title_fea= cate_fea.to(device), nume_fea.to(device) ,title_fea.to(device)\n",
    "            pred = model(cate_fea, nume_fea,title_fea).reshape(-1).data.cpu().numpy().tolist()\n",
    "            test_preds.extend(pred)\n",
    "        id_list = list(range(0, len(test_preds)))\n",
    "        out_dict = {\"id\": id_list, \"pred\": test_preds}\n",
    "        out_df = pd.DataFrame(out_dict)\n",
    "        out_df.to_csv('../../data/wj/deepfm_result/deepfm_result_title_'+modeln+'.csv', sep=',', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:00, 13.76it/s]\n"
     ]
    }
   ],
   "source": [
    "modeln='0.7809_3_7_12_15_15_04_09'\n",
    "model = DeepFM(cate_fea_nuniqs, nume_fea_size=len(dense_features))\n",
    "model.load_state_dict(torch.load('../../data/wj/deepfm_best/10 4.0/deepfm_best_10_title_'+modeln+'.pth'))\n",
    "\n",
    "device = torch.device('cuda:2') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = model.to(device)\n",
    "model.eval()  # 把模型转为test模式\n",
    "predict(df_test_user_doc, sparse_features, dense_features, model, device,modeln)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sw0",
   "language": "python",
   "name": "sw0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
