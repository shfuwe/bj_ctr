{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_pickle('../data/train0.1.pkl')\n",
    "df_test = pd.read_pickle('../data/test.pkl')\n",
    "df_train.index = range(len(df_train))\n",
    "doc_info = pd.read_pickle('../data/doc_info.pkl')\n",
    "user_info = pd.read_pickle('../data/user_info.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train['dt']\n",
    "del df_train['date']\n",
    "del df_train['duration']\n",
    "del df_train['position']\n",
    "\n",
    "del df_test['dt']\n",
    "del df_test['date']\n",
    "\n",
    "del doc_info['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_info['docid'] = doc_info['docid'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 347466/347466 [00:13<00:00, 26681.93it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "words=[[],[],[],[],[]]\n",
    "for i in tqdm(doc_info['keyword']):\n",
    "#     print(i)\n",
    "    key_one={}\n",
    "#     print(key_one)\n",
    "    splts = i.split(',')\n",
    "    for sp in splts:\n",
    "        split_=sp.split(':')\n",
    "        try:\n",
    "            score=float(split_[1])\n",
    "            key_one[split_[0]]=score\n",
    "        except:\n",
    "            continue\n",
    "#     print(key_one)\n",
    "    key_one = sorted(key_one.items(),key = lambda x:x[1],reverse = True)\n",
    "#     print(key_one)\n",
    "    for i in range(5):\n",
    "        try:\n",
    "            key_=key_one[i][0]\n",
    "#             print(key_)\n",
    "            words[i].append(key_)\n",
    "#             if key_ not in keywords_all:\n",
    "#                 keywords_all.append(key_)\n",
    "        except:\n",
    "            words[i].append('_#_#_#_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1737331\n",
      "253759\n"
     ]
    }
   ],
   "source": [
    "keywords_all=['_#_#_#_']\n",
    "print(len(keywords_all))\n",
    "for i in range(5):\n",
    "    keywords_all+=words[i]\n",
    "print(len(keywords_all))\n",
    "keywords_all=list(set(keywords_all))\n",
    "print(len(keywords_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword2id = dict(zip(keywords_all, range(1, len(keywords_all) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 347466/347466 [00:00<00:00, 1082774.78it/s]\n",
      "100%|██████████| 347466/347466 [00:00<00:00, 1142735.97it/s]\n",
      "100%|██████████| 347466/347466 [00:00<00:00, 1126722.24it/s]\n",
      "100%|██████████| 347466/347466 [00:00<00:00, 1179940.89it/s]\n",
      "100%|██████████| 347466/347466 [00:00<00:00, 1003889.17it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    for j in tqdm(range(len(words[i]))):\n",
    "        words[i][j]=keyword2id[words[i][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_info['keyword0'] = words[0]\n",
    "doc_info['keyword1'] = words[1]\n",
    "doc_info['keyword2'] = words[2]\n",
    "doc_info['keyword3'] = words[3]\n",
    "doc_info['keyword4'] = words[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del doc_info['keyword']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_pickle('../data/train2.pkl')\n",
    "df_test.to_pickle('../data/test2.pkl')\n",
    "doc_info.to_pickle('../data/doc_info2.pkl')\n",
    "user_info.to_pickle('../data/user_info2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_pickle('../data/train2.pkl')\n",
    "df_test = pd.read_pickle('../data/test2.pkl')\n",
    "doc_info = pd.read_pickle('../data/doc_info2.pkl')\n",
    "user_info = pd.read_pickle('../data/user_info2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_user=pd.merge(df_train,user_info,on='userid')\n",
    "df_train_user_doc=pd.merge(df_train_user,doc_info,on='docid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_user=pd.merge(df_test,user_info,on='userid')\n",
    "df_test_user_doc=pd.merge(df_test_user,doc_info,on='docid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_user_doc.sort_values(\"id\",inplace=True)\n",
    "df_test_user_doc.index = range(len(df_test_user_doc))\n",
    "del df_test_user_doc['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# import numpy as np\n",
    "# for i in df_train_user_doc.columns:\n",
    "#     print(i)\n",
    "#     for index,j in tqdm(enumerate(df_train_user_doc[i])):\n",
    "#         if np.isnan(j):\n",
    "#             print(df_train_user_doc[i].mean())\n",
    "#             df_train_user_doc[i][index]=df_train_user_doc[i].mean()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# print(df_train_user_doc.describe())\n",
    "# # 数据集概览\n",
    "# print(df_train_user_doc.head(5))\n",
    "# # 前5行\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# for i in tqdm(df_train_user_doc.columns):\n",
    "#     print(i)\n",
    "#     df_train_user_doc[i].fillna((df_train_user_doc[i].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in tqdm(df_test_user_doc.columns):\n",
    "#     print(i)\n",
    "#     df_test_user_doc[i].fillna((df_test_user_doc[i].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_columns = [x for x in df_train_user_doc.columns if x not in ['click','dt','date','duration','position']]\n",
    "X = df_train_user_doc[x_columns]      # 样本\n",
    "y = df_train_user_doc['click']    # 标签\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(random_state=9)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbm0 = GradientBoostingClassifier(random_state=9)\n",
    "gbm0.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr-accuracy: 0.8548\n",
      "tr-AUC: 0.663665\n",
      "val-accuracy: 0.8538\n",
      "val-AUC: 0.658323\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "print(\"tr-accuracy: %.4g\" % accuracy_score(y_train.values, gbm0.predict(x_train)))      # Accuracy : 0.9855\n",
    "print(\"tr-AUC: %f\" % roc_auc_score(y_train, gbm0.predict_proba(x_train)[:, 1]))      # AUC Score (Train): 0.910597\n",
    "\n",
    "print(\"val-accuracy: %.4g\" % accuracy_score(y_val, gbm0.predict(x_val)))      # Accuracy : 0.9825\n",
    "print(\"val-AUC: %f\" % roc_auc_score(y_val, gbm0.predict_proba(x_val)[:, 1]))      # AUC Score (Train): 0.827217"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(gbm0, '../data/gbm2.model')\n",
    "gbm0 = joblib.load('../data/gbm2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       userid      docid      timestamp  network  refresh  device  os  \\\n",
      "0  2204868548  464495940  1625011774995        2        4    1479   0   \n",
      "\n",
      "   province  city  age  gender        pubtime  picnum  category1st  \\\n",
      "0       224   506    2       2  1624955700000      23           11   \n",
      "\n",
      "   category2nd  keyword0  keyword1  keyword2  keyword3  keyword4  \n",
      "0           57    184203    218948    158186     64826     63258  \n"
     ]
    }
   ],
   "source": [
    "x_columns_0 = [x for x in df_test_user_doc.columns if x not in ['click','dt','date','duration','position']]\n",
    "X_0 = df_test_user_doc[x_columns_0]      # 样本\n",
    "print(X_0[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre_0=gbm0.predict_proba(X_0)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "end=time.time()\n",
    "def store_list(lsit,text_path):\n",
    "    ff = open(text_path, encoding='utf-8', mode='w')\n",
    "    for line_list in lsit:\n",
    "        ff.write(str(line_list))  # 写入一个新文件中\n",
    "        ff.write(\"\\n\")\n",
    "store_list(y_pre_0,'../data/y_pre2_'+str(end)+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bj2",
   "language": "python",
   "name": "bj2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
